{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import csv\n",
    "from csv import DictReader\n",
    "import requests\n",
    "import json\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "from pathlib import Path\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation types are listed at https://support.datacite.org/docs/eventdata-guide#relation-type-id. This script looks for the resources (subjects) that are related somehow to each dataset PID (object) in the given CSV or TXT file.\n",
    "\n",
    "I'm considering only the relation types that the Dataverse software will consider when displaying counts of citations for each dataset:\n",
    "- Is-cited-by\n",
    "- cites\n",
    "- is-supplement-to\n",
    "- is-supplemented-by\n",
    "- is-referenced-by\n",
    "- references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager to patch joblib to report into tqdm progress bar given as argument\n",
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n",
    "\n",
    "\n",
    "# Create function that adds \"citations\" information for a given DOI and\n",
    "# to a CSV file (citationsOutputFile)\n",
    "def get_citation_counts(doi, relationTypesList, citationsOutputFile):\n",
    "\n",
    "    dataciteEventsAPI = 'https://api.datacite.org/events'\n",
    "    # 'https://api.test.datacite.org/events?doi=10.7910/DVN/28075&relation-type-id=references&page[number]=1'\n",
    "\n",
    "    params = {\n",
    "        'doi': doi.replace('doi:', ''),\n",
    "        'page[number]': 1,\n",
    "        'page[size]': 1\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(dataciteEventsAPI, params=params)\n",
    "        relationData = response.json()\n",
    "\n",
    "        if relationData['meta']['total'] > 0:\n",
    "            for relationType in relationTypesList:\n",
    "\n",
    "                params['page[number]'] = 1\n",
    "                params['page[size]'] = 25\n",
    "                params['relation-type-id'] = relationType\n",
    "\n",
    "                try:\n",
    "                    response = requests.get(dataciteEventsAPI, params=params)\n",
    "                    relationData = response.json()\n",
    "\n",
    "                    totalPages = relationData['meta']['total-pages']\n",
    "\n",
    "                    if totalPages > 0:\n",
    "\n",
    "                        # Initialization for paginating through Search API results and showing progress\n",
    "                        condition = True\n",
    "\n",
    "                        while condition:\n",
    "                            # print(f\"\\tGetting citations from page {params['page[number]']} of {totalPages}\")\n",
    "                            response = requests.get(dataciteEventsAPI, params=params)\n",
    "                            relationData = response.json()\n",
    "                            for i in relationData['data']:\n",
    "                                subjectId = i['attributes']['subj-id']\n",
    "\n",
    "                                # Record relationship only if the subject is not a DataCite report\n",
    "                                if 'https://api.datacite.org/reports/' not in subjectId:\n",
    "\n",
    "                                    objectId = i['attributes']['obj-id']\n",
    "                                    relationType = i['attributes']['relation-type-id']\n",
    "                                    occurredAt = i['attributes']['occurred-at']\n",
    "                                    timeStamp = i['attributes']['timestamp']\n",
    "\n",
    "                                    # Write values of the three variables to a new row in the CSV\n",
    "                                    with open(citationsOutputFile, mode='a', newline='') as citation:\n",
    "                                        citation = csv.writer(citation, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                                        citation.writerow([subjectId, relationType, objectId, occurredAt, timeStamp])\n",
    "\n",
    "                            params['page[number]'] += 1\n",
    "                            condition = params['page[number]'] <= totalPages\n",
    "                except Exception as e:\n",
    "                    errorTimeString = time.strftime('%Y.%m.%d_%H.%M.%S')\n",
    "                    errorType = f'Call for {relationType} data failed'\n",
    "                    with open(errorLog, mode='a', newline='') as error:\n",
    "                        error = csv.writer(error, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        error.writerow([pid, errorType, e, errorTimeString])\n",
    "\n",
    "    except Exception as e:\n",
    "        errorType = 'Failed to get any data'\n",
    "        with open(errorLog, mode='a', newline='') as error:\n",
    "            error = csv.writer(error, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            error.writerow([pid, errorType, e, errorTimeString])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "relationTypesList = [\n",
    "    'Is-cited-by',\n",
    "    'cites',\n",
    "    'is-supplement-to',\n",
    "    'is-supplemented-by',\n",
    "    'is-referenced-by',\n",
    "    'references'\n",
    "]\n",
    "\n",
    "currrentWorkingDirectory = os.getcwd()\n",
    "\n",
    "# Enter path to text file containing list of dataset DOIs\n",
    "datasetPIDFile = str(Path(currrentWorkingDirectory + '/' + 'datasets.txt'))\n",
    "\n",
    "# Read in list of dataset PIDs from given CSV or text file\n",
    "datasetPIDs = []\n",
    "errorGettingEventData = []\n",
    "\n",
    "datasetPIDFile = open(datasetPIDFile, 'r')\n",
    "for datasetPID in datasetPIDFile:\n",
    "    datasetPIDs.append(datasetPID.rstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pidTotal = len(datasetPIDs)\n",
    "\n",
    "print(f'Searching for citations for {pidTotal} datasets')\n",
    "\n",
    "currentTimeString = time.strftime('%Y.%m.%d_%H.%M.%S')\n",
    "\n",
    "# Create CSV file for writing data requested from DataCite API\n",
    "citationsOutputFile = str(Path(currrentWorkingDirectory + '/' + f'citations_of_hdv_datasets_{currentTimeString}.csv'))\n",
    "with open(citationsOutputFile, mode='w', newline='') as opencsvfile:\n",
    "    opencsvfile = csv.writer(opencsvfile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    opencsvfile.writerow(['subject_id', 'relation_type', 'object_id', 'occured_at', 'timestamp'])\n",
    "\n",
    "# Create error log to record when the get_citation_counts fails to get citation information\n",
    "errorLog = str(Path(currrentWorkingDirectory + '/' + f'error_log_{currentTimeString}.csv'))\n",
    "with open(errorLog, 'w', newline='') as openErrorFile:\n",
    "    openErrorFile = csv.writer(openErrorFile, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    openErrorFile.writerow(['pid', 'error_type', 'error_message', 'error_timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Use joblib library to use multiple CPU cores to speed things up\n",
    "# and track progress using tqdm progress bars\n",
    "with tqdm_joblib(tqdm(bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}', total=pidTotal)) as progress_bar:\n",
    "    Parallel(n_jobs=4, backend='threading')(delayed(get_citation_counts)(pid, relationTypesList, citationsOutputFile) for pid in datasetPIDs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}