{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import, check and prepare data\n",
    "\n",
    "Import CSV files that contain:\n",
    "- The PIDs of all datasets published by many repositories that use the Dataverse software and which repositories published them\n",
    "- Author field metadata entered in all of those datasets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get basic info about datasets in repositories except for ODISSEI Portal\n",
    "datasetPIDsDF = (pd\n",
    "    .read_csv(\n",
    "        'dataset_pids_from_most_known_dataverse_installations_2023.08.csv',\n",
    "        sep=',',\n",
    "        na_filter=False)\n",
    "    .query(\n",
    "        '(dataverse_json_export_saved == True) and\\\n",
    "        (dataverse_installation_name != \"ODISSEI_Portal\")')\n",
    "    .drop(columns=['dataverse_json_export_saved'])\n",
    "    .reset_index(drop=True, inplace=False)\n",
    " )\n",
    "\n",
    "datasetPIDsDF.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get Author field metadata entered in all datasets in Dataverse repositories\n",
    "# and remove datasets have have no author metadata\n",
    "authorMetadataDF = (pd\n",
    "    .read_csv(\n",
    "        'author(citation)_2023.08.22-2023.08.28.csv',\n",
    "        sep=',',\n",
    "        na_filter=True,\n",
    "        parse_dates=['dataset_publication_date', 'dataset_version_create_time'])\n",
    "    .drop(columns=['dataset_pid', 'authorAffiliation'])\n",
    "    .query('authorName != \"N/A\"')\n",
    "    .reset_index(drop=True, inplace=False)\n",
    "    )\n",
    "\n",
    "authorMetadataDF.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sanity check data by making sure count of datasets is the same in both dataframes\n",
    "print(f'Number of datasets in datasetPIDsDF: {len(datasetPIDsDF)}')\n",
    "datasetCountInAuthorMetadataDF = len(pd.unique(authorMetadataDF['dataset_pid_url']))\n",
    "print(f'Number of datasets in authorMetadataDF: {datasetCountInAuthorMetadataDF}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Join the datasetPIDsDF and the authorMetadataDF to add the installation column,\n",
    "# so we know which installations published each dataset\n",
    "datasetPIDsAndAuthorMetadataDF = (pd\n",
    "    .merge(datasetPIDsDF, authorMetadataDF,\n",
    "        how='inner',\n",
    "        on=['dataset_pid_url'])\n",
    "    .drop(columns=['dataset_version_number'])\n",
    "    .reset_index(drop=True, inplace=False))\n",
    "\n",
    "# Make sure the count of datasets in datasetPIDsAndAuthorMetadataDF\n",
    "# is the same as in datasetPIDsDF: 390401\n",
    "datasetCountInDatasetPIDsAndAuthorMetadataDF = len(pd.unique(datasetPIDsAndAuthorMetadataDF['dataset_pid_url']))\n",
    "print(f'Number of datasets in datasetPIDsAndAuthorMetadataDF: {datasetCountInDatasetPIDsAndAuthorMetadataDF}')\n",
    "\n",
    "# Get count of author metadata\n",
    "print(f'Number of author metadata in datasetPIDsAndAuthorMetadataDF: {len(datasetPIDsAndAuthorMetadataDF)}')\n",
    "\n",
    "# Get count of installations. Should by 84: the 85 installations in my dataset minus ODISSEI Portal\n",
    "allInstallationsList = list(set(datasetPIDsAndAuthorMetadataDF['dataverse_installation_name'].tolist()))\n",
    "countOfInstallations = len(allInstallationsList)\n",
    "print(f'Number of installations in datasetPIDsAndAuthorMetadataDF: {countOfInstallations}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datasetPIDsAndAuthorMetadataDF.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Explore data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In a given time frame, such as 12 months, what percentage of author metadata published in each Dataverse installation includes an ORCID?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "publicationStartDate = '2022-01-01'\n",
    "publicationEndDate = '2022-12-31'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "allAuthorMetadataDf = (\n",
    "    datasetPIDsAndAuthorMetadataDF\n",
    "        .query(\n",
    "            'dataset_version_create_time >= @publicationStartDate and\\\n",
    "            dataset_version_create_time <= @publicationEndDate and\\\n",
    "            authorName != \"N/A\"',\n",
    "            engine='python')\n",
    "    .assign(dataset_version_create_time_dt=lambda datasetPIDsAndAuthorMetadataDF: pd.to_datetime(\n",
    "        datasetPIDsAndAuthorMetadataDF['dataset_version_create_time']))\n",
    "    .assign(dataset_version_create_year=lambda datasetPIDsAndAuthorMetadataDF: pd.to_datetime(\n",
    "        datasetPIDsAndAuthorMetadataDF['dataset_version_create_time_dt']).dt.year)\n",
    "    [[\n",
    "        'dataverse_installation_name',\n",
    "        'dataset_version_create_year',\n",
    "        'authorName',\n",
    "        'authorIdentifierScheme',\n",
    "        'authorIdentifier'\n",
    "    ]]\n",
    "    # Within each month, drop duplicate author metadata. This will mitigate the effect of\n",
    "    # hundreds or thousands of datasets being published with the same author metadata in a short\n",
    "    # time frame, such during a dataset migration or bulk publishing using APIs\n",
    "    .drop_duplicates(\n",
    "        subset=[\n",
    "            'authorName',\n",
    "            'authorIdentifierScheme',\n",
    "            'authorIdentifier'],\n",
    "        keep='first')\n",
    "    [[\n",
    "        'dataverse_installation_name',\n",
    "        'dataset_version_create_year'\n",
    "    ]]\n",
    "\n",
    "    .reset_index(drop=True, inplace=False)\n",
    "\n",
    "    # Group by count of rows for each year-month\n",
    "    .groupby(pd.Grouper(key='dataverse_installation_name', axis=0)).count()\n",
    "    .rename(columns={'dataset_version_create_year': 'count_of_author_metadata'})\n",
    "    .reset_index(drop=False, inplace=False)\n",
    ")\n",
    "\n",
    "allAuthorMetadataDf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(len(allAuthorMetadataDf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "orcidsDf = (\n",
    "    datasetPIDsAndAuthorMetadataDF\n",
    "        .query(\n",
    "            'dataset_version_create_time >= @publicationStartDate and\\\n",
    "            dataset_version_create_time <= @publicationEndDate and\\\n",
    "            (authorIdentifier.str.contains(\"orcid\", case=False) or\\\n",
    "            authorIdentifier.str.match(\".{4}-.{4}-.{4}-.{4}\") or\\\n",
    "            (authorIdentifierScheme == \"ORCID\" and\\\n",
    "            authorIdentifier == authorIdentifier))',\n",
    "            engine='python')\n",
    "    .drop(columns=[\n",
    "        'dataset_pid_url',\n",
    "        'dataverse_collection_alias',\n",
    "        'dataverse_collection_name',\n",
    "        'dataverse_collection_type'])\n",
    "    .assign(dataset_version_create_time_dt=lambda datasetPIDsAndAuthorMetadataDF: pd.to_datetime(\n",
    "        datasetPIDsAndAuthorMetadataDF['dataset_version_create_time']))\n",
    "    .assign(dataset_version_create_year=lambda datasetPIDsAndAuthorMetadataDF: pd.to_datetime(\n",
    "        datasetPIDsAndAuthorMetadataDF['dataset_version_create_time_dt']).dt.year)\n",
    "    [[\n",
    "        'dataverse_installation_name',\n",
    "        'dataset_version_create_year',\n",
    "        'authorName',\n",
    "        'authorIdentifierScheme',\n",
    "        'authorIdentifier'\n",
    "    ]]\n",
    "\n",
    "    # Within each month, drop duplicate metadata. This will mitigate the effect of\n",
    "    # hundreds or thousands of datasets being published with the same author metadata in a short\n",
    "    # time frame, such during a dataset migration or bulk publishing using APIs\n",
    "    .drop_duplicates(\n",
    "        subset=[\n",
    "            'authorName',\n",
    "            'authorIdentifierScheme',\n",
    "            'authorIdentifier'],\n",
    "        keep='first')\n",
    "    [[\n",
    "        'dataverse_installation_name',\n",
    "        'dataset_version_create_year'\n",
    "    ]]\n",
    "\n",
    "    .reset_index(drop=True, inplace=False)\n",
    "\n",
    "    # Group by count of rows for each year-month\n",
    "    .groupby(pd.Grouper(key='dataverse_installation_name', axis=0)).count()\n",
    "    .rename(columns={'dataset_version_create_year': 'count_of_orcids'})\n",
    "    .reset_index(drop=False, inplace=False)\n",
    ")\n",
    "\n",
    "orcidsDf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Merge the two dataframes\n",
    "allAuthorMetadataVersusORCIDsDf = (pd\n",
    "     .merge(allAuthorMetadataDf, orcidsDf,\n",
    "        how='outer',\n",
    "        on=['dataverse_installation_name'])\n",
    "     .fillna(0)\n",
    "     # Make dataverse_installation_name the index column\n",
    "     .set_index('dataverse_installation_name', inplace=False)\n",
    "     # Make sure all non-indexed columns are integers\n",
    "     .astype('int32')\n",
    "     .reset_index(drop=False, inplace=False)\n",
    "     )\n",
    "\n",
    "# Add column for percentage of ORCIDs\n",
    "allAuthorMetadataVersusORCIDsDf['percentage_of_orcids'] = (\n",
    "        (allAuthorMetadataVersusORCIDsDf['count_of_orcids']\n",
    "         / allAuthorMetadataVersusORCIDsDf['count_of_author_metadata'])\n",
    "        * 100\n",
    ")\n",
    "\n",
    "allAuthorMetadataVersusORCIDsDf.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Export the dataframe as a CSV file\n",
    "allAuthorMetadataVersusORCIDsDf.to_csv(\n",
    "    'allAuthorMetadataVersusORCIDs.csv',\n",
    "    index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}