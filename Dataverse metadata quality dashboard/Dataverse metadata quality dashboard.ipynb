{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Plan\" data-toc-modified-id=\"Plan-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Plan</a></span></li><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-modules-and-load-functions\" data-toc-modified-id=\"Import-modules-and-load-functions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import modules and load functions</a></span></li><li><span><a href=\"#Get-dataverse-info\" data-toc-modified-id=\"Get-dataverse-info-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Get dataverse info</a></span></li><li><span><a href=\"#Get-aliases-of-any-sub-dataverses-in-the-given-dataverse\" data-toc-modified-id=\"Get-aliases-of-any-sub-dataverses-in-the-given-dataverse-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Get aliases of any sub-dataverses in the given dataverse</a></span></li><li><span><a href=\"#Get-dataset-info\" data-toc-modified-id=\"Get-dataset-info-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Get dataset info</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "For chosen dataverse:\n",
    "    - Show dataverse info:\n",
    "        - Show number of subdataverses, if any\n",
    "        - Show whether or not the (sub)dataverse has a description or tagline\n",
    "        - List metadatablocks of each (sub)dataverse\n",
    "        - List the facets set for each (sub)dataverse\n",
    "        - Verify that contact email address is valid for each (sub)dataverse\n",
    "        (see https://medium.com/@arjunsinghy96/verify-emails-over-socks-proxy-using-python-5589cb75c405\n",
    "        and https://github.com/Gardener-gg/email-verifier)\n",
    "    - Show dataset info\n",
    "        - Show number of datasets\n",
    "        - Show date of first published dataset\n",
    "        - Show date of most recently published or updated dataset\n",
    "        - Show average age of datasets\n",
    "        - Show average number of dataset versions\n",
    "        - Metadata (of latest published version of each dataset):\n",
    "            - Show average number of characters in the dataset descriptions\n",
    "                - List datasets with fewer than a certain number of characters in their descriptions\n",
    "            - List datasets with CC0 or Terms of Use metadata\n",
    "                - Versus number of datasets with no CC0 or TOU metadata\n",
    "                - List datasets with no CC0 or TOU metadata\n",
    "            - Show number of files that have no description metadata\n",
    "                - If a certain percentage of datasets have 1 or more files with no descriptions, list those datasets\n",
    "            - Related publication metadata\n",
    "                - Show number of datasets with related publication metadata\n",
    "                    - List datasets with no related publication metadata\n",
    "                - Show number of datasets with no PID in related publication metadata\n",
    "                    - List datasets with no PID in related publication metadata\n",
    "            - Show datasets that have no metadata for any non-citation metadatablocks enabled in the dataverse\n",
    "        - Data\n",
    "            - List count of each unique file format\n",
    "            - Show number of datasets with no files\n",
    "                - List datasets that have no files\n",
    "            - Show number of datasets with 1 or more uningested tabular files\n",
    "                - List datasets that contain 1 or more uningested tabular files\n",
    "            - Show number of datasets with 1 or more restricted files\n",
    "        - Contact emails\n",
    "            - Get number of datasets that have a contact email address that's different email from the dataverse contact email address\n",
    "            - Get unique list of contact email addresses and check if they're valid\n",
    "            - Show any datasets that have no valid email addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def improved_get(_dict, path, default=None):\n",
    "    for key in path.split('.'):\n",
    "        try:\n",
    "            _dict = _dict[key]\n",
    "        except KeyError:\n",
    "            return default\n",
    "    return _dict\n",
    "\n",
    "\n",
    "def list_to_string(list):\n",
    "    # Alphabetize list in case-insensitive way\n",
    "    list = sorted(list, key=lambda s: s.casefold())\n",
    "\n",
    "    # Change list to comma-separated string\n",
    "    delimiter = \",\"\n",
    "    string = delimiter.join(list)\n",
    "    return string\n",
    "\n",
    "\n",
    "def string_to_list(string): \n",
    "    li = list(string.split(\",\")) \n",
    "    return li\n",
    "\n",
    "\n",
    "def string_to_datetime(string):\n",
    "    newDatetime = datetime.strptime(string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "    return newDatetime\n",
    "\n",
    "\n",
    "currentTime = datetime.now(timezone.utc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataverse info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataverse server and alias from user - return error if there's no alias or if alias is the Root dataverse\n",
    "server = 'https://demo.dataverse.org'\n",
    "mainDataverseAlias = 'sefsef'\n",
    "# server = 'https://dataverse.harvard.edu'\n",
    "# mainDataverseAlias = 'mit'\n",
    "\n",
    "repositoryMetadataBlocksApi = '%s/api/v1/metadatablocks' % (server)\n",
    "response = requests.get(repositoryMetadataBlocksApi)\n",
    "repositoryMetadataBlocks = response.json()\n",
    "\n",
    "repositoryMetadataBlockNames = []\n",
    "for repositoryMetadataBlock in repositoryMetadataBlocks['data']:\n",
    "    repositoryMetadataBlockNames.append(repositoryMetadataBlock['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info from that dataverse: whether or not the dataverse has a description and/or tagline, metadatablocks enabled, facets enabled, validate contact email\n",
    "dataverseInfoApi = '%s/api/dataverses/%s' % (server, mainDataverseAlias)\n",
    "response = requests.get(dataverseInfoApi)\n",
    "dataverseMetadata = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataverse description exists: False\n",
      "Dataverse tagline exists: False\n",
      "Number of search facets used: 6\n",
      "Number of metadatablocks enabled (in addition to Citation): 5\n",
      "\t['citation', 'biomedical', 'journal', 'astrophysics', 'socialscience', 'geospatial']\n"
     ]
    }
   ],
   "source": [
    "if dataverseMetadata['status'] == 'ERROR':\n",
    "    print('No dataverse found. Is the dataverse published on Harvard Dataverse?')\n",
    "elif dataverseMetadata['status'] == 'OK':\n",
    "    if 'description' in dataverseMetadata['data']:\n",
    "        dataverseMetadataExists = True\n",
    "    else:\n",
    "        dataverseMetadataExists = False\n",
    "    print('Dataverse description exists: %s' % (dataverseMetadataExists))\n",
    "\n",
    "    if 'theme' in dataverseMetadata['data'] and 'tagline' in dataverseMetadata['data']['theme']:\n",
    "        taglineExists = True\n",
    "    else:\n",
    "        taglineExists = False\n",
    "    print('Dataverse tagline exists: %s' % (taglineExists))\n",
    "\n",
    "#     contactEmails = []\n",
    "#     for contact in dataverseMetadata['data']['dataverseContacts']:\n",
    "#         contactEmails.append(contact['contactEmail'])\n",
    "#     print(contactEmails)\n",
    "\n",
    "    dataverseFacetsApi = '%s/api/dataverses/%s/facets' % (server, mainDataverseAlias)\n",
    "    response = requests.get(dataverseFacetsApi)\n",
    "    dataverseFacets = response.json()\n",
    "    facets = []\n",
    "    for facet in dataverseFacets['data']:\n",
    "        facets.append(facet)\n",
    "    print('Number of search facets used: %s' % (len(facets)))    \n",
    "\n",
    "#     # See if dataverse inherits its metadatablocks from its parent dataverse\n",
    "#     metadatablocksInheritedApi = '%s/api/dataverses/%s/metadatablocks/isRoot' % (server, dataverseAlias)\n",
    "#     response = requests.get(metadatablocksInheritedApi)\n",
    "#     metadatablocksInherited = response.json()\n",
    "#     print(metadatablocksInherited)\n",
    "    \n",
    "    # Get list of metadatablocks enabled in the dataverse\n",
    "    dataverseMetadatablocksList = []\n",
    "    dataverseMetadatablocksApi = '%s/api/dataverses/%s/metadatablocks' % (server, mainDataverseAlias)\n",
    "    response = requests.get(dataverseMetadatablocksApi)\n",
    "    dataverseMetadatablocks = response.json()\n",
    "    for dataverseMetadatablock in dataverseMetadatablocks['data']:\n",
    "        dataverseMetadatablock = dataverseMetadatablock['name']\n",
    "        dataverseMetadatablocksList.append(dataverseMetadatablock)\n",
    "    print('Number of metadatablocks enabled (in addition to Citation): %s' % (len(dataverseMetadatablocksList) - 1))\n",
    "    print('\\t%s' % (dataverseMetadatablocksList))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get aliases of any sub-dataverses in the given dataverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      "Found 1 dataverse and 2 subdataverses\n"
     ]
    }
   ],
   "source": [
    "mainDataverseInfoApi = '%s/api/dataverses/%s' % (server, mainDataverseAlias)\n",
    "response = requests.get(mainDataverseInfoApi)\n",
    "data = response.json()\n",
    "mainDataverseID = data['data']['id']\n",
    "\n",
    "dataverseIDs = [mainDataverseID]\n",
    "for dataverseID in dataverseIDs:\n",
    "\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    url = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    for i in data['data']:\n",
    "        if i['type'] == 'dataverse':\n",
    "            dataverseID = i['id']\n",
    "            dataverseIDs.extend([dataverseID])\n",
    "\n",
    "print('\\n\\nFound 1 dataverse and %s subdataverses' % (len(dataverseIDs) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "Number of datasets: 3\n"
     ]
    }
   ],
   "source": [
    "# Get PIDs of all published datasets in each of the dataverses\n",
    "datasetPIDs = []\n",
    "rowList = []\n",
    "for dataverseID in dataverseIDs:\n",
    "    getDataverseInfoApi = '%s/api/dataverses/%s' % (server, dataverseID)\n",
    "    response = requests.get(getDataverseInfoApi)\n",
    "    dataverseInfo = response.json()\n",
    "    dataverseName = dataverseInfo['data']['name']\n",
    "    dataverseAlias = dataverseInfo['data']['alias']\n",
    "\n",
    "    getDataverseContentsApi = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "    response = requests.get(getDataverseContentsApi)\n",
    "    dataverseContents = response.json()\n",
    "    for item in dataverseContents['data']:\n",
    "        if item['type'] == 'dataset':\n",
    "            datasetPID = item['persistentUrl'].replace('https://doi.org/', 'doi:')\n",
    "            datasetPIDs.append(datasetPID)\n",
    "            \n",
    "            newRow = {'datasetPID': datasetPID,\n",
    "                  'dataverseName': dataverseName,\n",
    "                  'dataverseUrl': '%s/dataverse/%s' % (server, dataverseAlias)\n",
    "                 }\n",
    "            rowList.append(dict(newRow))\n",
    "            \n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "print('\\nNumber of datasets: %s' % (len(datasetPIDs)))\n",
    "\n",
    "datasetDataverseInfoDF = pd.DataFrame(rowList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datasetPIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe for dataset info: date of publication, the release date of the latest version, number of versions\n",
    "\n",
    "_Getting this info can be slow. For example, getting the info of ~375 datasets might take 45 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 of 3 (doi:10.70122/FK2/ZYUGHH)\r"
     ]
    }
   ],
   "source": [
    "# Create list of file types that Dataverse can convert to .tab files during ingest\n",
    "uningestedFileTypes = ['application/x-rlang-transport', 'application/x-stata-13', 'application/x-spss-por',\n",
    "                      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'text/csv', 'text/tsv',\n",
    "                      'application/x-spss-sav', 'text/comma-separated-values', 'application/x-stata',\n",
    "                      'application/x-stata-14']\n",
    "\n",
    "rowList = []\n",
    "datasetCount = 0\n",
    "for datasetPID in datasetPIDs:\n",
    "    getAllVersionsApi = '%s/api/datasets/:persistentId/versions?persistentId=%s' % (server, datasetPID)\n",
    "    response = requests.get(getAllVersionsApi)\n",
    "    datasetVersions = response.json()\n",
    "    \n",
    "    # Get only datasets with metadata (exclude responses with no values in 'data' key, e.g. deaccessioned datasets)\n",
    "    if datasetVersions['status'] == 'OK' and len(datasetVersions['data']) > 0:\n",
    "        \n",
    "        # Get metadata of latest version\n",
    "        latestDatasetVersion = datasetVersions['data'][0]\n",
    "        \n",
    "        # Get index location of first dataset version\n",
    "        firstVersion = len(datasetVersions['data']) - 1\n",
    "\n",
    "        publicationDate = string_to_datetime(datasetVersions['data'][firstVersion]['releaseTime'])\n",
    "        latestReleaseDate = string_to_datetime(latestDatasetVersion['releaseTime'])\n",
    "        \n",
    "        # Get age of dataset from today's date\n",
    "        delta = currentTime - publicationDate\n",
    "        ageOfDataset = delta.days\n",
    "        \n",
    "        # Get number of days since last update\n",
    "        delta = currentTime - latestReleaseDate\n",
    "        ageOfLastUpdate = delta.days\n",
    "        if ageOfLastUpdate < 0:\n",
    "            ageOfLastUpdate = 0\n",
    "        \n",
    "        # Get length of description text\n",
    "        descriptionLength = 0\n",
    "        \n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'dsDescription':\n",
    "                # \"N/A\" is the value assigned there was no description given (pre Dataverse 4)\n",
    "                if len(field['value']) == 1 and field['value'][0]['dsDescriptionValue']['value'] == 'N/A':\n",
    "                    descriptionLength = 0\n",
    "                else:\n",
    "                    for i in field['value']:\n",
    "                        descriptionLength = descriptionLength + len(i['dsDescriptionValue']['value'])\n",
    "\n",
    "        # See whether CC0 or Terms of Use metadata exists\n",
    "        license = latestDatasetVersion.get('license', 'None')\n",
    "\n",
    "        if 'termsOfUse' in latestDatasetVersion:\n",
    "            termsOfUse = True\n",
    "        else:\n",
    "            termsOfUse = False\n",
    "            \n",
    "        if 'termsOfAccess' in latestDatasetVersion:\n",
    "            termsOfAccess = True\n",
    "        else:\n",
    "            termsOfAccess = False\n",
    "\n",
    "        if license != 'CC0' and termsOfUse == False:\n",
    "            termsExist = False\n",
    "        else:\n",
    "            termsExist = True\n",
    "\n",
    "        # Get info about related publication metadata\n",
    "        relPubCount = 0\n",
    "        relPubPIDCount = 0\n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'publication':\n",
    "                for value in field['value']:\n",
    "                    relPubCount += 1\n",
    "                    if 'publicationIDType' and 'publicationIDNumber' in value:\n",
    "                        relPubPIDCount += 1\n",
    "        \n",
    "        # Show metadatablocks whose fields are used by the dataset\n",
    "        usedMetadataBlocks = []\n",
    "        for repositoryMetadataBlockName in repositoryMetadataBlockNames:\n",
    "            try:\n",
    "                fieldCount = len(latestDatasetVersion['metadataBlocks'][repositoryMetadataBlockName]['fields'])\n",
    "                if fieldCount > 0:\n",
    "                    usedMetadataBlocks.append(repositoryMetadataBlockName)\n",
    "            except KeyError:\n",
    "                usedMetadataBlocks = usedMetadataBlocks\n",
    "        if len(usedMetadataBlocks) == 0:\n",
    "            usedMetadataBlocks = ''\n",
    "        else:\n",
    "            usedMetadataBlocks = list_to_string(usedMetadataBlocks)\n",
    "        \n",
    "        # Get number of files\n",
    "        numberOfFiles = len(latestDatasetVersion['files'])\n",
    "\n",
    "        # Get file info\n",
    "        noFileDescriptionCount = 0\n",
    "        contentType = []\n",
    "        ingestedTabFilesCount = 0\n",
    "        uningestedTabFilesCount = 0\n",
    "        restrictedFilesCount = 0\n",
    "        fileTags = []\n",
    "        for file in latestDatasetVersion['files']:            \n",
    "            if 'description' in file:\n",
    "                noFileDescriptionCount = noFileDescriptionCount\n",
    "            else:\n",
    "                noFileDescriptionCount += 1\n",
    "            contentType.append(file['dataFile']['contentType'])\n",
    "            if file['restricted'] == True:\n",
    "                restrictedFilesCount += 1\n",
    "            if file['dataFile']['contentType'] in uningestedFileTypes:\n",
    "                uningestedTabFilesCount += 1\n",
    "            if file['dataFile']['contentType'] == 'text/tab-separated-values':\n",
    "                ingestedTabFilesCount += 1\n",
    "            try:\n",
    "                for tags in file['categories']:\n",
    "                    fileTags.append(tags)\n",
    "            except KeyError:\n",
    "                fileTags = fileTags\n",
    "\n",
    "        tabularDataFileCount = uningestedTabFilesCount + ingestedTabFilesCount\n",
    "\n",
    "        if len(fileTags) == 0:\n",
    "            fileTagsExist = False\n",
    "        else:\n",
    "            fileTagsExist = True\n",
    "\n",
    "        if len(contentType) == 0:\n",
    "            uniqueContentTypes = 'NA'\n",
    "        else:\n",
    "            uniqueContentTypes = list_to_string(list(set(contentType)))\n",
    "\n",
    "        # Create dictionary\n",
    "        newRow = {'datasetPID': datasetPID,\n",
    "                  'datasetPIDUrl' : datasetPID.replace('doi:', 'https://doi.org/'),\n",
    "                  'numberOfVersions': len(datasetVersions['data']),\n",
    "                  'numberOfMajorVersions': latestDatasetVersion['versionNumber'],\n",
    "                  'publicationDate': publicationDate,\n",
    "                  'latestReleaseDate': latestReleaseDate,\n",
    "                  'ageOfDataset(Days)': ageOfDataset,\n",
    "                  'ageOfLastUpdate(Days)': ageOfLastUpdate,\n",
    "                  'descriptionLenth': descriptionLength,\n",
    "                  'termsExist': termsExist,\n",
    "                  'license': license,\n",
    "                  'termsOfUseExists': termsOfUse,\n",
    "                  'termsOfAccessExists': termsOfAccess,\n",
    "                  'relPubCount': relPubCount,\n",
    "                  'relPubPIDCount': relPubPIDCount,\n",
    "                  'usedMetadataBlocks': usedMetadataBlocks,\n",
    "                  'numberOfFiles': numberOfFiles,\n",
    "                  'noFileDescriptionCount': noFileDescriptionCount,\n",
    "                  'fileTagsExist': fileTagsExist,\n",
    "                  'uniqueContentTypes': uniqueContentTypes,\n",
    "                  'tabularDataFileCount': tabularDataFileCount,\n",
    "                  'ingestedTabFilesCount': ingestedTabFilesCount,\n",
    "                  'uningestedTabFilesCount': uningestedTabFilesCount,\n",
    "                  'restrictedFilesCount': restrictedFilesCount\n",
    "                 }\n",
    "        rowList.append(dict(newRow))\n",
    "        datasetCount += 1\n",
    "        print('%s of %s (%s)' % (datasetCount, len(datasetPIDs), datasetPID), end='\\r', flush=True)\n",
    "        \n",
    "if len(datasetPIDs) != datasetCount:\n",
    "    print('The metadata of %s dataset(s) could not be retrieved' % (len(datasetPIDs) - datasetCount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetInfoDF = pd.DataFrame(rowList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [datasetDataverseInfoDF, datasetInfoDF]\n",
    "\n",
    "# For each dataframe, set the indexes (or the common columns across the dataframes to join on)\n",
    "for dataframe in dataframes:\n",
    "    dataframe.set_index(['datasetPID'], inplace=True)\n",
    "\n",
    "# Merge both dataframes and save to the 'merged' variable\n",
    "report = reduce(lambda left, right: left.join(right, how='outer'), dataframes)\n",
    "\n",
    "# Reset index\n",
    "report.reset_index(drop=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetPID</th>\n",
       "      <th>dataverseName</th>\n",
       "      <th>dataverseUrl</th>\n",
       "      <th>datasetPIDUrl</th>\n",
       "      <th>numberOfVersions</th>\n",
       "      <th>numberOfMajorVersions</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>latestReleaseDate</th>\n",
       "      <th>ageOfDataset(Days)</th>\n",
       "      <th>ageOfLastUpdate(Days)</th>\n",
       "      <th>...</th>\n",
       "      <th>relPubPIDCount</th>\n",
       "      <th>usedMetadataBlocks</th>\n",
       "      <th>numberOfFiles</th>\n",
       "      <th>noFileDescriptionCount</th>\n",
       "      <th>fileTagsExist</th>\n",
       "      <th>uniqueContentTypes</th>\n",
       "      <th>tabularDataFileCount</th>\n",
       "      <th>ingestedTabFilesCount</th>\n",
       "      <th>uningestedTabFilesCount</th>\n",
       "      <th>restrictedFilesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doi:10.70122/FK2/HZTO03</td>\n",
       "      <td>Julian Gautier (SU) Dataverse</td>\n",
       "      <td>https://demo.dataverse.org/dataverse/sefsef</td>\n",
       "      <td>https://doi.org/10.70122/FK2/HZTO03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 19:48:40+00:00</td>\n",
       "      <td>2020-10-26 03:44:39+00:00</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>citation,geospatial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doi:10.70122/FK2/CMFTOD</td>\n",
       "      <td>Julian Gautier (SU) Dataverse</td>\n",
       "      <td>https://demo.dataverse.org/dataverse/sefsef</td>\n",
       "      <td>https://doi.org/10.70122/FK2/CMFTOD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-14 20:07:47+00:00</td>\n",
       "      <td>2020-10-14 20:07:47+00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>citation</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>image/jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doi:10.70122/FK2/ZYUGHH</td>\n",
       "      <td>Julian Gautier (SU) Dataverse</td>\n",
       "      <td>https://demo.dataverse.org/dataverse/sefsef</td>\n",
       "      <td>https://doi.org/10.70122/FK2/ZYUGHH</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-17 16:08:53+00:00</td>\n",
       "      <td>2020-10-29 03:16:38+00:00</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>astrophysics,biomedical,citation,geospatial,so...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>image/jpeg,image/png,text/tab-separated-values</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datasetPID                  dataverseName  \\\n",
       "0  doi:10.70122/FK2/HZTO03  Julian Gautier (SU) Dataverse   \n",
       "1  doi:10.70122/FK2/CMFTOD  Julian Gautier (SU) Dataverse   \n",
       "2  doi:10.70122/FK2/ZYUGHH  Julian Gautier (SU) Dataverse   \n",
       "\n",
       "                                  dataverseUrl  \\\n",
       "0  https://demo.dataverse.org/dataverse/sefsef   \n",
       "1  https://demo.dataverse.org/dataverse/sefsef   \n",
       "2  https://demo.dataverse.org/dataverse/sefsef   \n",
       "\n",
       "                         datasetPIDUrl  numberOfVersions  \\\n",
       "0  https://doi.org/10.70122/FK2/HZTO03                 3   \n",
       "1  https://doi.org/10.70122/FK2/CMFTOD                 1   \n",
       "2  https://doi.org/10.70122/FK2/ZYUGHH                16   \n",
       "\n",
       "   numberOfMajorVersions           publicationDate         latestReleaseDate  \\\n",
       "0                      1 2020-08-04 19:48:40+00:00 2020-10-26 03:44:39+00:00   \n",
       "1                      1 2020-10-14 20:07:47+00:00 2020-10-14 20:07:47+00:00   \n",
       "2                      5 2020-09-17 16:08:53+00:00 2020-10-29 03:16:38+00:00   \n",
       "\n",
       "   ageOfDataset(Days)  ageOfLastUpdate(Days)  ...  relPubPIDCount  \\\n",
       "0                  86                      3  ...               0   \n",
       "1                  15                     15  ...               0   \n",
       "2                  42                      0  ...               1   \n",
       "\n",
       "                                  usedMetadataBlocks numberOfFiles  \\\n",
       "0                                citation,geospatial             0   \n",
       "1                                           citation             2   \n",
       "2  astrophysics,biomedical,citation,geospatial,so...             3   \n",
       "\n",
       "   noFileDescriptionCount  fileTagsExist  \\\n",
       "0                       0          False   \n",
       "1                       2          False   \n",
       "2                       2           True   \n",
       "\n",
       "                               uniqueContentTypes  tabularDataFileCount  \\\n",
       "0                                              NA                     0   \n",
       "1                                      image/jpeg                     0   \n",
       "2  image/jpeg,image/png,text/tab-separated-values                     1   \n",
       "\n",
       "  ingestedTabFilesCount  uningestedTabFilesCount  restrictedFilesCount  \n",
       "0                     0                        0                     0  \n",
       "1                     0                        0                     0  \n",
       "2                     1                        0                     0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export report to CSV\n",
    "file = '%s_%s.csv' % (mainDataverseAlias, currentTime)\n",
    "report.to_csv(file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report = pd.read_csv('nds_datasets.csv', na_filter = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get list of metadatablocks used by all datasets\n",
    "# allUsedMetadataBlocks = []\n",
    "# for i in report['usedMetadataBlocks']:\n",
    "#     allUsedMetadataBlocks.extend(list(i.split(\",\")))\n",
    "\n",
    "# # Deduplicate, alphabetize and change list to string\n",
    "# allUsedMetadataBlocks = list_to_string(list(set(allUsedMetadataBlocks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/octet-stream,application/pdf,application/vnd.ms-excel,text/tab-separated-values: <class 'str'>\n",
      "NA: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/pdf,text/plain: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII,text/tab-separated-values: <class 'str'>\n",
      "text/plain; charset=US-ASCII,text/tab-separated-values: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/msword,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,text/tab-separated-values: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII,text/tab-separated-values: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/msword,application/octet-stream,text/plain: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/pdf,text/tab-separated-values: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel,application/zip,text/tab-separated-values: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel,application/zip,text/plain,text/tab-separated-values: <class 'str'>\n",
      "application/dbf,application/octet-stream,application/pdf,application/vnd.ms-excel,application/zip,text/tab-separated-values: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel,application/zip,text/tab-separated-values: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/octet-stream,application/pdf,application/vnd.ms-excel,text/plain: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/pdf: <class 'str'>\n",
      "application/dbf,application/msword,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/octet-stream,application/pdf,application/vnd.ms-excel,application/x-rar-compressed,text/plain,text/tab-separated-values: <class 'str'>\n",
      "application/octet-stream,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "application/pdf,text/tab-separated-values: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/octet-stream,application/pdf,text/plain: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,application/octet-stream,text/plain: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,application/octet-stream,text/plain: <class 'str'>\n",
      "application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "NA: <class 'str'>\n",
      "application/octet-stream,application/pdf,application/vnd.ms-excel,text/plain,text/tab-separated-values: <class 'str'>\n",
      "application/pdf,text/tab-separated-values: <class 'str'>\n",
      "application/dbf,application/pdf,text/plain: <class 'str'>\n",
      "application/octet-stream,application/pdf,application/vnd.ms-excel,text/plain: <class 'str'>\n",
      "application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,application/vnd.ms-excel,application/vnd.openxmlformats-officedocument.spreadsheetml.sheet: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII,text/tab-separated-values: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/pdf,text/tab-separated-values: <class 'str'>\n",
      "application/octet-stream,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/pdf,text/tab-separated-values: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/octet-stream: <class 'str'>\n",
      "application/octet-stream,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "NA: <class 'str'>\n",
      "application/pdf,application/vnd.ms-excel,text/plain: <class 'str'>\n",
      "application/pdf,application/vnd.ms-excel,text/plain: <class 'str'>\n",
      "application/pdf,application/vnd.ms-excel,text/plain: <class 'str'>\n",
      "application/pdf,application/vnd.ms-excel,text/plain: <class 'str'>\n",
      "application/msword,application/pdf,application/vnd.ms-excel,text/tab-separated-values: <class 'str'>\n",
      "application/msword,application/pdf,application/vnd.ms-excel,text/html,text/plain,text/x-fixed-field: <class 'str'>\n",
      "application/pdf,application/vnd.ms-excel,text/plain: <class 'str'>\n",
      "application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,application/rar,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/pdf,text/plain; charset=US-ASCII,text/tab-separated-values,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel,text/plain: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/pdf,text/plain: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/dbf,application/msword,text/plain: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/pdf: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel,text/plain: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel,text/tab-separated-values: <class 'str'>\n",
      "application/dbf,text/plain: <class 'str'>\n",
      "application/pdf,text/tab-separated-values: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII,text/x-spss-syntax; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/pdf,application/zip,text/tab-separated-values: <class 'str'>\n",
      "application/dbf,application/pdf,application/vnd.ms-excel: <class 'str'>\n",
      "application/msword,application/octet-stream,application/vnd.ms-excel: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/vnd.ms-excel,text/plain; charset=US-ASCII: <class 'str'>\n",
      "text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/pdf,text/plain; charset=US-ASCII: <class 'str'>\n",
      "application/msword,application/vnd.ms-excel: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,application/x-sas-syntax,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,application/x-sas-syntax,text/tab-separated-values,text/x-fixed-field: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n",
      "application/pdf,application/x-sas-syntax,text/tab-separated-values,text/x-fixed-field: <class 'str'>\n",
      "application/pdf,text/tab-separated-values,text/x-fixed-field,text/x-sas-syntax: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# for i in report['uniqueContentTypes']:\n",
    "#     print('%s: %s' % (i, type(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Get list of uniqueContentTypes used by all datasets\n",
    "# allContentTypes = []\n",
    "# for i in report['uniqueContentTypes']:\n",
    "#     if i != 'NA':\n",
    "#         allContentTypes.extend(list(i.split(\",\")))\n",
    "\n",
    "# # Deduplicate, alphabetize and change list to string\n",
    "# # allContentTypes = list_to_string(list(set(allContentTypes)))\n",
    "# len(set(allContentTypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'tabularDataFileCount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tabularDataFileCount'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-333-9521cd21d5e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;34m'16'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fileTagsExist'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdatasetCount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;34m'17'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallContentTypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;34m'18'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tabularDataFileCount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdatasetCount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;34m'19'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ingestedTabFilesCount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtabularDataFileCount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;34m'20'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uningestedTabFilesCount'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtabularDataFileCount\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tabularDataFileCount'"
     ]
    }
   ],
   "source": [
    "# # Create summary\n",
    "# summaryDict = {\n",
    "#     'Summary': {\n",
    "#         '0': 'Has description',\n",
    "#         '1': 'Has tagline',\n",
    "#         '2': 'Number of search facets',\n",
    "#         '3': 'Metadatablocks enabled',\n",
    "#         '4': 'Dataset count',\n",
    "#         '5': 'Versions (avg # of major and minor versions)',\n",
    "#         '6': 'Major versions (average #)',\n",
    "#         '7': 'Description length (avg # of characters)',\n",
    "#         '8': 'CC0 datasets (% of total datasets)',\n",
    "#         '9': 'Age of datasets (average)',\n",
    "#         '10': 'No terms (% of datasets with no terms metadata)',\n",
    "#         '11': 'Related pub metadata (% of datasets with rel pub metadata)',\n",
    "#         '12': 'Related pub PIDs (% of datasets with rel pub PIDs)',\n",
    "#         '13': 'Metadatablocks used (list)',\n",
    "#         '14': 'No files (# of datasets with no files)',\n",
    "#         '15': 'File descriptions (% of datasets with 1 or more file descriptions)',\n",
    "#         '16': 'File tags (% of datasets with 1 or more file tags)',\n",
    "#         '17': 'Unique file types (count)',\n",
    "#         '18': 'Tabular data (% of datasets with tabular data) ',\n",
    "#         '19': 'Tabular data ingest successes (% of datasets with tabular data that has been ingested)',\n",
    "#         '20': 'Tabular data ingest failures (% of datasets with tabular data that has not been ingested)',\n",
    "#         '21': 'Public files (% of unrestricted files)'\n",
    "#     },\n",
    "#     mainDataverseAlias: {\n",
    "#         '0': dataverseMetadataExists,\n",
    "#         '1': taglineExists,\n",
    "#         '2': len(facets),\n",
    "#         '3': len(dataverseMetadatablocksList) - 1,\n",
    "#         '4': datasetCount,\n",
    "#         '5': report['numberOfVersions'].mean(),\n",
    "#         '6': report['numberOfMajorVersions'].mean(),\n",
    "#         '7': report['descriptionLenth'].mean(),\n",
    "#         '8': (len(report['license']=='CC0')/datasetCount)*100,\n",
    "#         '9': report['ageOfDataset(Days)'].mean(),\n",
    "#         '10': ((~report['termsExist']).values.sum())/datasetCount*100,\n",
    "#         '11': len(report[(report['relPubCount']!=0)])/datasetCount*100,\n",
    "#         '12': len(report[(report['relPubPIDCount']!=0)])/datasetCount*100,\n",
    "#         '13': allUsedMetadataBlocks,\n",
    "#         '14': len(report[(report['numberOfFiles']==0)]),\n",
    "#         '15': len(report[(report['noFileDescriptionCount']!=0)])/datasetCount*100,\n",
    "#         '16': ((report['fileTagsExist']).values.sum())/datasetCount*100,\n",
    "#         '17': len(set(allContentTypes)),\n",
    "#         '18': len(report[(report['tabularDataFileCount']!=0)])/datasetCount*100,\n",
    "#         '19': len(report[(report['ingestedTabFilesCount']!=0)])/tabularDataFileCount*100,\n",
    "#         '20': len(report[(report['uningestedTabFilesCount']!=0)])/tabularDataFileCount*100,\n",
    "#         '21': len(report[(report['restrictedFilesCount']==0)])\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # # Show average age of datasets\n",
    "# # ageOfDatasets = report['ageOfDataset(Days)'].mean()\n",
    "# # averageDatasetAge = ageOfDatasets.mean()\n",
    "\n",
    "# # # Show average number of dataset versions\n",
    "# # numberOfVersions = report['numberOfVersions'].mean()\n",
    "# # averageNumberOfVersions = numberOfVersions.mean()\n",
    "\n",
    "# # # Create list of datasets with fewer than a certain number of characters in their descriptions\n",
    "# # lowDescriptionCount = df[df['descriptionLenth'] < 20]\n",
    "# # lowDescriptionCount = lowDescriptionCount['datasetPID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetInfoDF = pd.DataFrame(summaryDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Summary</th>\n",
       "      <th>sefsef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has description</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Has tagline</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Number of search facets</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Metadatablocks enabled</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset count</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Versions (avg # of major and minor versions)</td>\n",
       "      <td>6.66667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Major versions (average #)</td>\n",
       "      <td>2.33333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Description length (avg # of characters)</td>\n",
       "      <td>4.66667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CC0 datasets (% of total datasets)</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Age of datasets (average)</td>\n",
       "      <td>47.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>No terms (% of datasets with no terms metadata)</td>\n",
       "      <td>33.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Related pub metadata (% of datasets with rel p...</td>\n",
       "      <td>33.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Related pub PIDs (% of datasets with rel pub P...</td>\n",
       "      <td>33.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Metadatablocks used (list)</td>\n",
       "      <td>astrophysics,biomedical,citation,geospatial,so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>No files (# of datasets with no files)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>File descriptions (% of datasets with 1 or mor...</td>\n",
       "      <td>66.6667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>File tags (% of datasets with 1 or more file t...</td>\n",
       "      <td>33.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Unique file types (count)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tabular data (% of datasets with tabular data)</td>\n",
       "      <td>33.3333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tabular data ingest successes (% of datasets w...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Tabular data ingest failures (% of datasets wi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Public files (% of unrestricted files)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Summary  \\\n",
       "0                                     Has description   \n",
       "1                                         Has tagline   \n",
       "2                             Number of search facets   \n",
       "3                              Metadatablocks enabled   \n",
       "4                                       Dataset count   \n",
       "5        Versions (avg # of major and minor versions)   \n",
       "6                          Major versions (average #)   \n",
       "7            Description length (avg # of characters)   \n",
       "8                  CC0 datasets (% of total datasets)   \n",
       "9                           Age of datasets (average)   \n",
       "10    No terms (% of datasets with no terms metadata)   \n",
       "11  Related pub metadata (% of datasets with rel p...   \n",
       "12  Related pub PIDs (% of datasets with rel pub P...   \n",
       "13                         Metadatablocks used (list)   \n",
       "14             No files (# of datasets with no files)   \n",
       "15  File descriptions (% of datasets with 1 or mor...   \n",
       "16  File tags (% of datasets with 1 or more file t...   \n",
       "17                          Unique file types (count)   \n",
       "18    Tabular data (% of datasets with tabular data)    \n",
       "19  Tabular data ingest successes (% of datasets w...   \n",
       "20  Tabular data ingest failures (% of datasets wi...   \n",
       "21             Public files (% of unrestricted files)   \n",
       "\n",
       "                                               sefsef  \n",
       "0                                               False  \n",
       "1                                               False  \n",
       "2                                                   6  \n",
       "3                                                   5  \n",
       "4                                                   3  \n",
       "5                                             6.66667  \n",
       "6                                             2.33333  \n",
       "7                                             4.66667  \n",
       "8                                                 100  \n",
       "9                                             47.6667  \n",
       "10                                            33.3333  \n",
       "11                                            33.3333  \n",
       "12                                            33.3333  \n",
       "13  astrophysics,biomedical,citation,geospatial,so...  \n",
       "14                                                  1  \n",
       "15                                            66.6667  \n",
       "16                                            33.3333  \n",
       "17                                                  3  \n",
       "18                                            33.3333  \n",
       "19                                                100  \n",
       "20                                                  0  \n",
       "21                                                  3  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasetInfoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List count of each unique file format"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
