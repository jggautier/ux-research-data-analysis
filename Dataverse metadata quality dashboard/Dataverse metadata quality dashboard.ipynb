{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Plan\" data-toc-modified-id=\"Plan-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Plan</a></span></li><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Code</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-modules-and-load-functions\" data-toc-modified-id=\"Import-modules-and-load-functions-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import modules and load functions</a></span></li><li><span><a href=\"#Get-dataverse-info\" data-toc-modified-id=\"Get-dataverse-info-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Get dataverse info</a></span></li><li><span><a href=\"#Get-aliases-of-any-sub-dataverses-in-the-given-dataverse\" data-toc-modified-id=\"Get-aliases-of-any-sub-dataverses-in-the-given-dataverse-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Get aliases of any sub-dataverses in the given dataverse</a></span></li><li><span><a href=\"#Get-dataset-info\" data-toc-modified-id=\"Get-dataset-info-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Get dataset info</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "hide_input": false
   },
   "source": [
    "For chosen dataverse:\n",
    "    - Show dataverse info:\n",
    "        - Show number of subdataverses, if any\n",
    "        - Show whether or not the (sub)dataverse has a description or tagline\n",
    "        - List metadatablocks of each (sub)dataverse\n",
    "        - List the facets set for each (sub)dataverse\n",
    "        - Verify that contact email address is valid for each (sub)dataverse\n",
    "        (see https://medium.com/@arjunsinghy96/verify-emails-over-socks-proxy-using-python-5589cb75c405\n",
    "        and https://github.com/Gardener-gg/email-verifier)\n",
    "    - Show dataset info\n",
    "        - Show number of datasets\n",
    "        - Show date of first published dataset\n",
    "        - Show date of most recently published or updated dataset\n",
    "        - Show average age of datasets\n",
    "        - Show average number of dataset versions\n",
    "        - Metadata (of latest published version of each dataset):\n",
    "            - Show average number of characters in the dataset descriptions\n",
    "                - List datasets with fewer than a certain number of characters in their descriptions\n",
    "            - List datasets with CC0 or Terms of Use metadata\n",
    "                - Versus number of datasets with no CC0 or TOU metadata\n",
    "                - List datasets with no CC0 or TOU metadata\n",
    "            - Show number of files that have no description metadata\n",
    "                - If a certain percentage of datasets have 1 or more files with no descriptions, list those datasets\n",
    "            - Related publication metadata\n",
    "                - Show number of datasets with related publication metadata\n",
    "                    - List datasets with no related publication metadata\n",
    "                - Show number of datasets with no PID in related publication metadata\n",
    "                    - List datasets with no PID in related publication metadata\n",
    "            - Show datasets that have no metadata for any non-citation metadatablocks enabled in the dataverse\n",
    "        - Data\n",
    "            - List count of each unique file format\n",
    "            - Show number of datasets with no files\n",
    "                - List datasets that have no files\n",
    "            - Show number of datasets with 1 or more uningested tabular files\n",
    "                - List datasets that contain 1 or more uningested tabular files\n",
    "            - Show number of datasets with 1 or more restricted files\n",
    "        - Contact emails\n",
    "            - Get number of datasets that have a contact email address that's different email from the dataverse contact email address\n",
    "            - Get unique list of contact email addresses and check if they're valid\n",
    "            - Show any datasets that have no valid email addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "def improved_get(_dict, path, default=None):\n",
    "    for key in path.split('.'):\n",
    "        try:\n",
    "            _dict = _dict[key]\n",
    "        except KeyError:\n",
    "            return default\n",
    "    return _dict\n",
    "\n",
    "\n",
    "def list_to_string(list):\n",
    "    # Alphabetize list in case-insensitive way\n",
    "    list = sorted(list, key=lambda s: s.casefold())\n",
    "    # Change list to comma-separated string\n",
    "    delimiter = \",\"\n",
    "    string = delimiter.join(list)\n",
    "    return string\n",
    "\n",
    "\n",
    "def string_to_datetime(string):\n",
    "    newDatetime = datetime.strptime(string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "    return newDatetime\n",
    "\n",
    "# current_time = str.strftime('%Y.%m.%d_%H.%M.%S')\n",
    "# current_time = datetime.strftime('%Y-%m-%dT%H:%M:%S%z')\n",
    "# currentTime = datetime.now()\n",
    "currentTime = datetime.now(timezone.utc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataverse info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataverse server and alias from user - return error if there's no alias or if alias is the Root dataverse\n",
    "server = 'https://demo.dataverse.org'\n",
    "mainDataverseAlias = 'sefsef'\n",
    "# server = 'https://dataverse.harvard.edu'\n",
    "# mainDataverseAlias = 'nds'\n",
    "\n",
    "repositoryMetadataBlocksApi = '%s/api/v1/metadatablocks' % (server)\n",
    "response = requests.get(repositoryMetadataBlocksApi)\n",
    "repositoryMetadataBlocks = response.json()\n",
    "\n",
    "repositoryMetadataBlockNames = []\n",
    "for repositoryMetadataBlock in repositoryMetadataBlocks['data']:\n",
    "    repositoryMetadataBlockNames.append(repositoryMetadataBlock['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info from that dataverse: whether or not the dataverse has a description and/or tagline, metadatablocks enabled, facets enabled, validate contact email\n",
    "dataverseInfoApi = '%s/api/dataverses/%s' % (server, mainDataverseAlias)\n",
    "response = requests.get(dataverseInfoApi)\n",
    "dataverseMetadata = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataverse has no description\n",
      "Dataverse has no tagline\n",
      "Number of search facets used: 6\n",
      "Number of metadatablocks enabled (in addition to Citation): 5\n"
     ]
    }
   ],
   "source": [
    "if dataverseMetadata['status'] == 'ERROR':\n",
    "    print('No dataverse found. Is the dataverse published on Harvard Dataverse?')\n",
    "elif dataverseMetadata['status'] == 'OK':\n",
    "    dataverseDescription = improved_get(dataverseMetadata, 'data.description')\n",
    "    if dataverseDescription is not None:\n",
    "        print('Dataverse has a description')\n",
    "    else:\n",
    "        print('Dataverse has no description')\n",
    "\n",
    "    tagline = improved_get(dataverseMetadata, 'data.theme.tagline')\n",
    "    if tagline is not None:\n",
    "        print('Dataverse has a tagline')\n",
    "    else:\n",
    "        print('Dataverse has no tagline')\n",
    "\n",
    "#     contactEmails = []\n",
    "#     for contact in dataverseMetadata['data']['dataverseContacts']:\n",
    "#         contactEmails.append(contact['contactEmail'])\n",
    "#     print(contactEmails)\n",
    "\n",
    "    dataverseFacetsApi = '%s/api/dataverses/%s/facets' % (server, mainDataverseAlias)\n",
    "    response = requests.get(dataverseFacetsApi)\n",
    "    dataverseFacets = response.json()\n",
    "    facets = []\n",
    "    for facet in dataverseFacets['data']:\n",
    "        facets.append(facet)\n",
    "    print('Number of search facets used: %s' % (len(facets)))    \n",
    "\n",
    "#     # See if dataverse inherits its metadatablocks from its parent dataverse\n",
    "#     metadatablocksInheritedApi = '%s/api/dataverses/%s/metadatablocks/isRoot' % (server, dataverseAlias)\n",
    "#     response = requests.get(metadatablocksInheritedApi)\n",
    "#     metadatablocksInherited = response.json()\n",
    "#     print(metadatablocksInherited)\n",
    "    \n",
    "    # Get list of metadatablocks enabled in the dataverse\n",
    "    dataverseMetadatablocksList = []\n",
    "    dataverseMetadatablocksApi = '%s/api/dataverses/%s/metadatablocks' % (server, mainDataverseAlias)\n",
    "    response = requests.get(dataverseMetadatablocksApi)\n",
    "    dataverseMetadatablocks = response.json()\n",
    "    for dataverseMetadatablock in dataverseMetadatablocks['data']:\n",
    "        dataverseMetadatablock = dataverseMetadatablock['name']\n",
    "        dataverseMetadatablocksList.append(dataverseMetadatablock)\n",
    "    print('Number of metadatablocks enabled (in addition to Citation): %s' % (len(dataverseMetadatablocksList) - 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get aliases of any sub-dataverses in the given dataverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n",
      "\n",
      "Found 1 dataverse and 2 subdataverses\n"
     ]
    }
   ],
   "source": [
    "mainDataverseInfoApi = '%s/api/dataverses/%s' % (server, mainDataverseAlias)\n",
    "response = requests.get(mainDataverseInfoApi)\n",
    "data = response.json()\n",
    "mainDataverseID = data['data']['id']\n",
    "\n",
    "dataverseIDs = [mainDataverseID]\n",
    "for dataverseID in dataverseIDs:\n",
    "\n",
    "    sys.stdout.write('.')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    url = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    for i in data['data']:\n",
    "        if i['type'] == 'dataverse':\n",
    "            dataverseID = i['id']\n",
    "            dataverseIDs.extend([dataverseID])\n",
    "\n",
    "print('\\n\\nFound 1 dataverse and %s subdataverses' % (len(dataverseIDs) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Number of datasets: 3\n"
     ]
    }
   ],
   "source": [
    "# Get PIDs of all published datasets in each of the dataverses\n",
    "datasetPIDs = []\n",
    "rowList = []\n",
    "for dataverseID in dataverseIDs:\n",
    "    getDataverseInfoApi = '%s/api/dataverses/%s' % (server, dataverseID)\n",
    "    response = requests.get(getDataverseInfoApi)\n",
    "    dataverseInfo = response.json()\n",
    "    dataverseName = dataverseInfo['data']['name']\n",
    "    dataverseAlias = dataverseInfo['data']['alias']\n",
    "\n",
    "    getDataverseContentsApi = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "    response = requests.get(getDataverseContentsApi)\n",
    "    dataverseContents = response.json()\n",
    "    for item in dataverseContents['data']:\n",
    "        if item['type'] == 'dataset':\n",
    "            datasetPID = item['persistentUrl'].replace('https://doi.org/', 'doi:')\n",
    "            datasetPIDs.append(datasetPID)\n",
    "            \n",
    "            newRow = {'datasetPID': datasetPID,\n",
    "                  'dataverseName': dataverseName,\n",
    "                  'dataverseUrl': '%s/dataverse/%s' % (server, dataverseAlias)\n",
    "                 }\n",
    "            rowList.append(dict(newRow))\n",
    "            \n",
    "            sys.stdout.write('.')\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "print('\\nNumber of datasets: %s' % (len(datasetPIDs)))\n",
    "\n",
    "datasetDataverseInfoDF = pd.DataFrame(rowList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(datasetPIDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe for dataset info: date of publication, the release date of the latest version, number of versions\n",
    "\n",
    "_Getting this info can be slow. For example, getting the info of ~375 datasets might take 45 min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 of 3 (doi:10.70122/FK2/ZYUGHH)\r"
     ]
    }
   ],
   "source": [
    "# Create list of file types that Dataverse can convert to .tab files during ingest\n",
    "uningestedFileTypes = ['application/x-rlang-transport', 'application/x-stata-13', 'application/x-spss-por',\n",
    "                      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'text/csv', 'text/tsv',\n",
    "                      'application/x-spss-sav', 'text/comma-separated-values', 'application/x-stata',\n",
    "                      'application/x-stata-14']\n",
    "\n",
    "rowList = []\n",
    "datasetCount = 0\n",
    "for datasetPID in datasetPIDs:\n",
    "    getAllVersionsApi = '%s/api/datasets/:persistentId/versions?persistentId=%s' % (server, datasetPID)\n",
    "    response = requests.get(getAllVersionsApi)\n",
    "    datasetVersions = response.json()\n",
    "    \n",
    "    # Get only datasets with metadata (exclude responses with no values in 'data' key, e.g. deaccessioned datasets)\n",
    "    if datasetVersions['status'] == 'OK' and len(datasetVersions['data']) > 0:\n",
    "        \n",
    "        # Get metadata of latest version\n",
    "        latestDatasetVersion = datasetVersions['data'][0]\n",
    "        \n",
    "        # Get index location of first dataset version\n",
    "        firstVersion = len(datasetVersions['data']) - 1\n",
    "\n",
    "        publicationDate = string_to_datetime(datasetVersions['data'][firstVersion]['releaseTime'])\n",
    "        latestReleaseDate = string_to_datetime(latestDatasetVersion['releaseTime'])\n",
    "        \n",
    "        # Get age of dataset from today's date\n",
    "        delta = currentTime - publicationDate\n",
    "        ageOfDataset = delta.days\n",
    "        \n",
    "        # Get number of days since last update\n",
    "        delta = currentTime - latestReleaseDate\n",
    "        ageOfLastUpdate = delta.days\n",
    "        if ageOfLastUpdate < 0:\n",
    "            ageOfLastUpdate = 0\n",
    "        \n",
    "        # Get length of description text\n",
    "        descriptionLength = 0\n",
    "        \n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'dsDescription':\n",
    "                # \"N/A\" is the value assigned there was no description given (pre Dataverse 4)\n",
    "                if len(field['value']) == 1 and field['value'][0]['dsDescriptionValue']['value'] == 'N/A':\n",
    "                    descriptionLength = 0\n",
    "                else:\n",
    "                    for i in field['value']:\n",
    "                        descriptionLength = descriptionLength + len(i['dsDescriptionValue']['value'])\n",
    "\n",
    "        # See whether CC0 or Terms of Use metadata exists\n",
    "        license = latestDatasetVersion.get('license', 'None')\n",
    "\n",
    "        if 'termsOfUse' in latestDatasetVersion:\n",
    "            termsOfUse = True\n",
    "        else:\n",
    "            termsOfUse = False\n",
    "            \n",
    "        if 'termsOfAccess' in latestDatasetVersion:\n",
    "            termsOfAccess = True\n",
    "        else:\n",
    "            termsOfAccess = False\n",
    "\n",
    "        if license != 'CC0' and termsOfUse == False:\n",
    "            termsExist = False\n",
    "        else:\n",
    "            termsExist = True\n",
    "\n",
    "        # Get info about related publication metadata\n",
    "        relPubCount = 0\n",
    "        relPubPIDCount = 0\n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'publication':\n",
    "                for value in field['value']:\n",
    "                    relPubCount += 1\n",
    "                    if 'publicationIDType' and 'publicationIDNumber' in value:\n",
    "                        relPubPIDCount += 1\n",
    "        \n",
    "        # Show metadatablocks whose fields are used by the dataset\n",
    "        usedMetadataBlocks = []\n",
    "        for repositoryMetadataBlockName in repositoryMetadataBlockNames:\n",
    "            try:\n",
    "                fieldCount = len(latestDatasetVersion['metadataBlocks'][repositoryMetadataBlockName]['fields'])\n",
    "                if fieldCount > 0:\n",
    "                    usedMetadataBlocks.append(repositoryMetadataBlockName)\n",
    "            except KeyError:\n",
    "                usedMetadataBlocks = usedMetadataBlocks\n",
    "        if len(usedMetadataBlocks) == 0:\n",
    "            usedMetadataBlocks = ''\n",
    "        else:\n",
    "            usedMetadataBlocks = list_to_string(usedMetadataBlocks)\n",
    "        \n",
    "        # Get number of files\n",
    "        numberOfFiles = len(latestDatasetVersion['files'])\n",
    "\n",
    "        # Get file info\n",
    "        noFileDescriptionCount = 0\n",
    "        contentType = []\n",
    "        ingestedTabFilesCount = 0\n",
    "        uningestedTabFilesCount = 0\n",
    "        restrictedFilesCount = 0\n",
    "        fileTags = []\n",
    "        for file in latestDatasetVersion['files']:            \n",
    "            if 'description' in file:\n",
    "                noFileDescriptionCount = noFileDescriptionCount\n",
    "            else:\n",
    "                noFileDescriptionCount += 1\n",
    "            contentType.append(file['dataFile']['contentType'])\n",
    "            if file['restricted'] == True:\n",
    "                restrictedFilesCount += 1\n",
    "            if file['dataFile']['contentType'] in uningestedFileTypes:\n",
    "                uningestedTabFilesCount += 1\n",
    "            if file['dataFile']['contentType'] == 'text/tab-separated-values':\n",
    "                ingestedTabFilesCount += 1\n",
    "            try:\n",
    "                for tags in file['categories']:\n",
    "                    fileTags.append(tags)\n",
    "            except KeyError:\n",
    "                fileTags = fileTags\n",
    "\n",
    "        if len(fileTags) == 0:\n",
    "            fileTagsExist = False\n",
    "        else:\n",
    "            fileTagsExist = True\n",
    "\n",
    "        if len(contentType) == 0:\n",
    "            uniqueContentTypes = 'NA'\n",
    "        else:\n",
    "            uniqueContentTypes = list_to_string(list(set(contentType)))\n",
    "\n",
    "        # Create dictionary\n",
    "        newRow = {'datasetPID': datasetPID,\n",
    "                  'datasetPIDUrl' : datasetPID.replace('doi:', 'https://doi.org/'),\n",
    "                  'numberOfVersions': len(datasetVersions['data']),\n",
    "                  'numberOfMajorVersions': latestDatasetVersion['versionNumber'],\n",
    "                  'publicationDate': publicationDate,\n",
    "                  'latestReleaseDate': latestReleaseDate,\n",
    "                  'ageOfDataset(Days)': ageOfDataset,\n",
    "                  'ageOfLastUpdate(Days)': ageOfLastUpdate,\n",
    "                  'descriptionLenth': descriptionLength,\n",
    "                  'termsExist': termsExist,\n",
    "                  'license': license,\n",
    "                  'termsOfUseExists': termsOfUse,\n",
    "                  'termsOfAccessExists': termsOfAccess,\n",
    "                  'relPubCount': relPubCount,\n",
    "                  'relPubPIDCount': relPubPIDCount,\n",
    "                  'usedMetadataBlocks': usedMetadataBlocks,\n",
    "                  'numberOfFiles': numberOfFiles,\n",
    "                  'noFileDescriptionCount': noFileDescriptionCount,\n",
    "                  'fileTagsExist': fileTagsExist,\n",
    "                  'uniqueContentTypes': uniqueContentTypes,\n",
    "                  'ingestedTabFilesCount': ingestedTabFilesCount,\n",
    "                  'uningestedTabFilesCount': uningestedTabFilesCount,\n",
    "                  'restrictedFilesCount': restrictedFilesCount\n",
    "                 }\n",
    "        rowList.append(dict(newRow))\n",
    "        datasetCount += 1\n",
    "        print('%s of %s (%s)' % (datasetCount, len(datasetPIDs), datasetPID), end='\\r', flush=True)\n",
    "        \n",
    "if len(datasetPIDs) != datasetCount:\n",
    "    print('The metadata of %s dataset(s) could not be retrieved' % (len(datasetPIDs) - datasetCount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetPID</th>\n",
       "      <th>datasetPIDUrl</th>\n",
       "      <th>numberOfVersions</th>\n",
       "      <th>numberOfMajorVersions</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>latestReleaseDate</th>\n",
       "      <th>ageOfDataset(Days)</th>\n",
       "      <th>ageOfLastUpdate(Days)</th>\n",
       "      <th>descriptionLenth</th>\n",
       "      <th>termsExist</th>\n",
       "      <th>...</th>\n",
       "      <th>relPubCount</th>\n",
       "      <th>relPubPIDCount</th>\n",
       "      <th>usedMetadataBlocks</th>\n",
       "      <th>numberOfFiles</th>\n",
       "      <th>noFileDescriptionCount</th>\n",
       "      <th>fileTagsExist</th>\n",
       "      <th>uniqueContentTypes</th>\n",
       "      <th>ingestedTabFilesCount</th>\n",
       "      <th>uningestedTabFilesCount</th>\n",
       "      <th>restrictedFilesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doi:10.70122/FK2/HZTO03</td>\n",
       "      <td>https://doi.org/10.70122/FK2/HZTO03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 19:48:40+00:00</td>\n",
       "      <td>2020-10-26 03:44:39+00:00</td>\n",
       "      <td>85</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>citation,geospatial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doi:10.70122/FK2/CMFTOD</td>\n",
       "      <td>https://doi.org/10.70122/FK2/CMFTOD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-14 20:07:47+00:00</td>\n",
       "      <td>2020-10-14 20:07:47+00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>citation</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>image/jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doi:10.70122/FK2/ZYUGHH</td>\n",
       "      <td>https://doi.org/10.70122/FK2/ZYUGHH</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-17 16:08:53+00:00</td>\n",
       "      <td>2020-10-29 03:16:38+00:00</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>astrophysics,biomedical,citation,geospatial,so...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>image/jpeg,image/png,text/tab-separated-values</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datasetPID                        datasetPIDUrl  \\\n",
       "0  doi:10.70122/FK2/HZTO03  https://doi.org/10.70122/FK2/HZTO03   \n",
       "1  doi:10.70122/FK2/CMFTOD  https://doi.org/10.70122/FK2/CMFTOD   \n",
       "2  doi:10.70122/FK2/ZYUGHH  https://doi.org/10.70122/FK2/ZYUGHH   \n",
       "\n",
       "   numberOfVersions  numberOfMajorVersions           publicationDate  \\\n",
       "0                 3                      1 2020-08-04 19:48:40+00:00   \n",
       "1                 1                      1 2020-10-14 20:07:47+00:00   \n",
       "2                16                      5 2020-09-17 16:08:53+00:00   \n",
       "\n",
       "          latestReleaseDate  ageOfDataset(Days)  ageOfLastUpdate(Days)  \\\n",
       "0 2020-10-26 03:44:39+00:00                  85                      2   \n",
       "1 2020-10-14 20:07:47+00:00                  14                     14   \n",
       "2 2020-10-29 03:16:38+00:00                  41                      0   \n",
       "\n",
       "   descriptionLenth  termsExist  ... relPubCount  relPubPIDCount  \\\n",
       "0                 7       False  ...           0               0   \n",
       "1                 7        True  ...           0               0   \n",
       "2                 0        True  ...           2               1   \n",
       "\n",
       "                                  usedMetadataBlocks  numberOfFiles  \\\n",
       "0                                citation,geospatial              0   \n",
       "1                                           citation              2   \n",
       "2  astrophysics,biomedical,citation,geospatial,so...              3   \n",
       "\n",
       "   noFileDescriptionCount fileTagsExist  \\\n",
       "0                       0         False   \n",
       "1                       2         False   \n",
       "2                       2          True   \n",
       "\n",
       "                               uniqueContentTypes  ingestedTabFilesCount  \\\n",
       "0                                              NA                      0   \n",
       "1                                      image/jpeg                      0   \n",
       "2  image/jpeg,image/png,text/tab-separated-values                      1   \n",
       "\n",
       "   uningestedTabFilesCount restrictedFilesCount  \n",
       "0                        0                    0  \n",
       "1                        0                    0  \n",
       "2                        0                    0  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetInfoDF = pd.DataFrame(rowList)\n",
    "datasetInfoDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [datasetDataverseInfoDF, datasetInfoDF]\n",
    "\n",
    "# For each dataframe, set the indexes (or the common columns across the dataframes to join on)\n",
    "for dataframe in dataframes:\n",
    "    dataframe.set_index(['datasetPID'], inplace=True)\n",
    "\n",
    "# Merge both dataframes and save to the 'merged' variable\n",
    "report = reduce(lambda left, right: left.join(right, how='outer'), dataframes)\n",
    "\n",
    "# Reset index\n",
    "report.reset_index(drop=False, inplace=True)\n",
    "\n",
    "file = '%s_datasets.csv' % (mainDataverseAlias)\n",
    "report.to_csv(file, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Show date of first published dataset\n",
    "# publicationDates = df['publicationDate']\n",
    "# firstPublicationDate = publicationDates.min()\n",
    "\n",
    "# # Show date of most recently published or updated dataset\n",
    "# latestReleaseDates = df['latestReleaseDate']\n",
    "# lastReleaseDate = latestReleaseDates.min()\n",
    "\n",
    "# # Show age of most recently published or updated dataset\n",
    "# ageOfLastUpdates = df['ageOfLastUpdate']\n",
    "# ageOfLastUpdate = ageOfLastUpdates.min()\n",
    "\n",
    "# # Show average age of datasets\n",
    "# ageOfDatasets = df['ageOfDataset(Days)']\n",
    "# averageAge = ageOfDatasets.mean()\n",
    "\n",
    "# # Show average number of dataset versions\n",
    "# numberOfVersions = df['numberOfVersions']\n",
    "# averageNumberOfVersions = numberOfVersions.mean()\n",
    "\n",
    "# # Create list of datasets with fewer than a certain number of characters in their descriptions\n",
    "# lowDescriptionCount = df[df['descriptionLenth'] < 20]\n",
    "# lowDescriptionCount = lowDescriptionCount['datasetPID']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List count of each unique file format"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
