{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-modules-and-load-functions\" data-toc-modified-id=\"Import-modules-and-load-functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import modules and load functions</a></span></li><li><span><a href=\"#Load-misc.-functions\" data-toc-modified-id=\"Load-misc.-functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load misc. functions</a></span></li><li><span><a href=\"#Get-dataverse-info\" data-toc-modified-id=\"Get-dataverse-info-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Get dataverse info</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-IDs-of-any-sub-dataverses-in-the-given-dataverse\" data-toc-modified-id=\"Get-IDs-of-any-sub-dataverses-in-the-given-dataverse-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Get IDs of any sub-dataverses in the given dataverse</a></span></li></ul></li><li><span><a href=\"#Get-dataset-info\" data-toc-modified-id=\"Get-dataset-info-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Get dataset info</a></span><ul class=\"toc-item\"><li><span><a href=\"#Get-dataset-IDs-and-(sub)dataverse-names\" data-toc-modified-id=\"Get-dataset-IDs-and-(sub)dataverse-names-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Get dataset IDs and (sub)dataverse names</a></span></li><li><span><a href=\"#Collect-info-about-each-dataset-and-files\" data-toc-modified-id=\"Collect-info-about-each-dataset-and-files-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Collect info about each dataset and files</a></span></li></ul></li><li><span><a href=\"#Export-report-to-CSV\" data-toc-modified-id=\"Export-report-to-CSV-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Export report to CSV</a></span></li><li><span><a href=\"#Get-existing-dataverse-data\" data-toc-modified-id=\"Get-existing-dataverse-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Get existing dataverse data</a></span></li><li><span><a href=\"#Create-summary-stats-of-dataverse\" data-toc-modified-id=\"Create-summary-stats-of-dataverse-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Create summary stats of dataverse</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "from functools import reduce\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "\n",
    "# def improved_get(_dict, path, default=None):\n",
    "#     for key in path.split('.'):\n",
    "#         try:\n",
    "#             _dict = _dict[key]\n",
    "#         except KeyError:\n",
    "#             return default\n",
    "#     return _dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load misc. functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def list_to_string(list):\n",
    "    # Alphabetize list in case-insensitive way\n",
    "    list = sorted(list, key=lambda s: s.casefold())\n",
    "\n",
    "    # Change list to comma-separated string\n",
    "    delimiter = \",\"\n",
    "    string = delimiter.join(list)\n",
    "    return string\n",
    "\n",
    "\n",
    "def string_to_list(string): \n",
    "    li = list(string.split(\",\")) \n",
    "    return li\n",
    "\n",
    "\n",
    "def string_to_datetime(string):\n",
    "    dateTime = datetime.strptime(string, '%Y-%m-%dT%H:%M:%S%z')\n",
    "    return dateTime\n",
    "\n",
    "\n",
    "currentTime = datetime.now(timezone.utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get dataverse info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataverse server and alias from user - return error if there's no alias or if alias is the Root dataverse\n",
    "mainDataverseUrl = 'https://dataverse.harvard.edu/dataverse/mit'\n",
    "\n",
    "parsed = urlparse(mainDataverseUrl)\n",
    "server = parsed.scheme + '://' + parsed.netloc\n",
    "try:\n",
    "    mainDataverseAlias = parsed.path.split('/')[2]\n",
    "except IndexError:\n",
    "    mainDataverseAlias = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repository_metadatablocks(server):\n",
    "    repositoryMetadataBlocksApi = '%s/api/v1/metadatablocks' % (server)\n",
    "    response = requests.get(repositoryMetadataBlocksApi)\n",
    "    repositoryMetadataBlocks = response.json()\n",
    "\n",
    "    repositoryMetadataBlockNames = []\n",
    "    for repositoryMetadataBlock in repositoryMetadataBlocks['data']:\n",
    "        repositoryMetadataBlockNames.append(repositoryMetadataBlock['name'])\n",
    "    return repositoryMetadataBlockNames\n",
    "\n",
    "repositoryMetadataBlockNames = get_repository_metadatablocks(server)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Get metadata about dataverse\n",
    "def get_main_dataverse_json(mainDataverseUrl):\n",
    "    dataverseInfoApi = '%s/api/dataverses/%s' % (server, mainDataverseAlias)\n",
    "    response = requests.get(dataverseInfoApi)\n",
    "    dataverseMetadata = response.json()\n",
    "    return dataverseMetadata\n",
    "\n",
    "dataverseMetadata = get_main_dataverse_json(mainDataverseUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "if dataverseMetadata['status'] == 'ERROR':\n",
    "    print('No dataverse found. Is the dataverse published on Harvard Dataverse?')\n",
    "\n",
    "if dataverseMetadata['status'] == 'OK':\n",
    "    def dataverse_description_exists():\n",
    "        if 'description' in dataverseMetadata['data']:\n",
    "            dataverseDescriptionExists = True\n",
    "        else:\n",
    "            dataverseDescriptionExists = False\n",
    "        return dataverseDescriptionExists\n",
    "\n",
    "\n",
    "    def dataverse_tagline_exists():\n",
    "        if 'theme' in dataverseMetadata['data'] and 'tagline' in dataverseMetadata['data']['theme']:\n",
    "            taglineExists = True\n",
    "        else:\n",
    "            taglineExists = False\n",
    "        return taglineExists\n",
    "\n",
    "\n",
    "    def dataverse_facets():\n",
    "        dataverseFacetsApi = '%s/api/dataverses/%s/facets' % (server, mainDataverseAlias)\n",
    "        response = requests.get(dataverseFacetsApi)\n",
    "        dataverseFacets = response.json()\n",
    "        facets = []\n",
    "        for facet in dataverseFacets['data']:\n",
    "            facets.append(facet)\n",
    "        return facets\n",
    "\n",
    "\n",
    "    def dataverse_metadatablocks():\n",
    "        dataverseMetadatablocksApi = '%s/api/dataverses/%s/metadatablocks' % (server, mainDataverseAlias)\n",
    "        response = requests.get(dataverseMetadatablocksApi)\n",
    "        dataverseMetadatablocks = response.json()\n",
    "        dataverseMetadatablocksList = []\n",
    "        for dataverseMetadatablock in dataverseMetadatablocks['data']:\n",
    "            dataverseMetadatablocksList.append(dataverseMetadatablock['name'])\n",
    "        return dataverseMetadatablocksList\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get IDs of any sub-dataverses in the given dataverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1 dataverse and 0 subdataverses\n"
     ]
    }
   ],
   "source": [
    "def dataverse_ids():\n",
    "    mainDataverseID = dataverseMetadata['data']['id']\n",
    "    dataverseIDs = [mainDataverseID]\n",
    "    for dataverseID in dataverseIDs:\n",
    "\n",
    "#         sys.stdout.write('.')\n",
    "#         sys.stdout.flush()\n",
    "\n",
    "        getContentsApi = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "\n",
    "        response = requests.get(getContentsApi)\n",
    "        dataverseContents = response.json()\n",
    "\n",
    "        for i in dataverseContents['data']:\n",
    "            if i['type'] == 'dataverse':\n",
    "                dataverseID = i['id']\n",
    "                dataverseIDs.extend([dataverseID])\n",
    "    return dataverseIDs\n",
    "\n",
    "print('\\nFound 1 dataverse and %s subdataverses' % (len(dataverse_ids()) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get dataset info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Get dataset IDs and (sub)dataverse names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get PIDs of all published datasets in each of the dataverses\n",
    "def get_datasets():\n",
    "    datasetPIDs = []\n",
    "    datasetInfoDict = []\n",
    "    for dataverseID in dataverse_ids():\n",
    "        getDataverseInfoApi = '%s/api/dataverses/%s' % (server, dataverseID)\n",
    "        response = requests.get(getDataverseInfoApi)\n",
    "        dataverseInfo = response.json()\n",
    "        dataverseName = dataverseInfo['data']['name']\n",
    "        dataverseAlias = dataverseInfo['data']['alias']\n",
    "\n",
    "        getDataverseContentsApi = '%s/api/dataverses/%s/contents' % (server, dataverseID)\n",
    "        response = requests.get(getDataverseContentsApi)\n",
    "        dataverseContents = response.json()\n",
    "        for item in dataverseContents['data']:\n",
    "            if item['type'] == 'dataset':\n",
    "                datasetPID = item['persistentUrl'].replace('https://doi.org/', 'doi:')\n",
    "                datasetPIDs.append(datasetPID)\n",
    "\n",
    "                newRow = {'datasetPID': datasetPID,\n",
    "                      'dataverseName': dataverseName,\n",
    "                      'dataverseUrl': '%s/dataverse/%s' % (server, dataverseAlias)\n",
    "                     }\n",
    "                datasetInfoDict.append(dict(newRow))\n",
    "\n",
    "#                 sys.stdout.write('.')\n",
    "#                 sys.stdout.flush()\n",
    "    datasetDataverseInfoDF = pd.DataFrame(datasetInfoDict)\n",
    "    return datasetDataverseInfoDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(get_datasets().index)# len(report.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a dataframe for dataset info: date of publication, the release date of the latest version, number of versions\n",
    "\n",
    "_Getting this info can be slow. For example, getting the info of ~375 datasets might take 45 min_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Collect info about each dataset and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 of 48 (doi:10.7910/DVN/WOKBPF)\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-b71d37b86971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mrowList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewRow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0mdatasetCount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s of %s (%s)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatasetCount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasetPID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdatasetCount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-66-f05972693ab2>\u001b[0m in \u001b[0;36mget_datasets\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdataverseID\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataverse_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mgetDataverseInfoApi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s/api/dataverses/%s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataverseID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetDataverseInfoApi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mdataverseInfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdataverseName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataverseInfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    531\u001b[0m         }\n\u001b[1;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    447\u001b[0m                     \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                     \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                 )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sock\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mca_cert_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mca_cert_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mssl_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         )\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password)\u001b[0m\n\u001b[1;32m    368\u001b[0m     ) or IS_SECURETRANSPORT:\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         warnings.warn(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         )\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m    848\u001b[0m                         \u001b[0;31m# non-blocking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 850\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    851\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create list of file types that Dataverse can convert to .tab files during ingest\n",
    "uningestedFileTypes = ['application/x-rlang-transport', 'application/x-stata-13', 'application/x-spss-por',\n",
    "                      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet', 'text/csv', 'text/tsv',\n",
    "                      'application/x-spss-sav', 'text/comma-separated-values', 'application/x-stata',\n",
    "                      'application/x-stata-14']\n",
    "\n",
    "rowList = []\n",
    "datasetCount = 0\n",
    "for datasetPID in get_datasets()['datasetPID']:\n",
    "    getAllVersionsApi = '%s/api/datasets/:persistentId/versions?persistentId=%s' % (server, datasetPID)\n",
    "    response = requests.get(getAllVersionsApi)\n",
    "    datasetVersions = response.json()\n",
    "    \n",
    "    # Get only datasets with metadata (exclude responses with no values in 'data' key, e.g. deaccessioned datasets)\n",
    "    if datasetVersions['status'] == 'OK' and len(datasetVersions['data']) > 0:\n",
    "        \n",
    "        # Get metadata of latest version\n",
    "        latestDatasetVersion = datasetVersions['data'][0]\n",
    "        \n",
    "        # Get index location of first dataset version\n",
    "        firstVersion = len(datasetVersions['data']) - 1\n",
    "\n",
    "        publicationDate = string_to_datetime(datasetVersions['data'][firstVersion]['releaseTime'])\n",
    "        latestReleaseDate = string_to_datetime(latestDatasetVersion['releaseTime'])\n",
    "        \n",
    "        # Get age of dataset from today's date\n",
    "        delta = currentTime - publicationDate\n",
    "        ageOfDataset = delta.days\n",
    "        \n",
    "        # Get number of days since last update\n",
    "        delta = currentTime - latestReleaseDate\n",
    "        ageOfLastUpdate = delta.days\n",
    "        if ageOfLastUpdate < 0:\n",
    "            ageOfLastUpdate = 0\n",
    "        \n",
    "        # Get length of description text\n",
    "        descriptionLength = 0\n",
    "        \n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'dsDescription':\n",
    "                # \"N/A\" is the value assigned there was no description given (pre Dataverse 4)\n",
    "                if len(field['value']) == 1 and field['value'][0]['dsDescriptionValue']['value'] == 'N/A':\n",
    "                    descriptionLength = 0\n",
    "                else:\n",
    "                    for i in field['value']:\n",
    "                        descriptionLength = descriptionLength + len(i['dsDescriptionValue']['value'])\n",
    "\n",
    "        # See whether CC0 or Terms of Use metadata exists\n",
    "        license = latestDatasetVersion.get('license', 'None')\n",
    "\n",
    "        if 'termsOfUse' in latestDatasetVersion:\n",
    "            termsOfUse = True\n",
    "        else:\n",
    "            termsOfUse = False\n",
    "            \n",
    "        if 'termsOfAccess' in latestDatasetVersion:\n",
    "            termsOfAccess = True\n",
    "        else:\n",
    "            termsOfAccess = False\n",
    "\n",
    "        if license != 'CC0' and termsOfUse == False:\n",
    "            termsExist = False\n",
    "        else:\n",
    "            termsExist = True\n",
    "\n",
    "        # Get info about related publication metadata\n",
    "        relPubCount = 0\n",
    "        relPubPIDCount = 0\n",
    "        for field in latestDatasetVersion['metadataBlocks']['citation']['fields']:\n",
    "            if field['typeName'] == 'publication':\n",
    "                for value in field['value']:\n",
    "                    relPubCount += 1\n",
    "                    if 'publicationIDType' and 'publicationIDNumber' in value:\n",
    "                        relPubPIDCount += 1\n",
    "        \n",
    "        # Show metadatablocks whose fields are used by the dataset\n",
    "        usedMetadataBlocks = []\n",
    "        for repositoryMetadataBlockName in repositoryMetadataBlockNames:\n",
    "            try:\n",
    "                fieldCount = len(latestDatasetVersion['metadataBlocks'][repositoryMetadataBlockName]['fields'])\n",
    "                if fieldCount > 0:\n",
    "                    usedMetadataBlocks.append(repositoryMetadataBlockName)\n",
    "            except KeyError:\n",
    "                usedMetadataBlocks = usedMetadataBlocks\n",
    "        if len(usedMetadataBlocks) == 0:\n",
    "            usedMetadataBlocks = ''\n",
    "        else:\n",
    "            usedMetadataBlocks = list_to_string(usedMetadataBlocks)\n",
    "        \n",
    "        # Get number of files\n",
    "        numberOfFiles = len(latestDatasetVersion['files'])\n",
    "\n",
    "        # Get file info\n",
    "        noFileDescriptionCount = 0\n",
    "        contentType = []\n",
    "        ingestedTabFilesCount = 0\n",
    "        uningestedTabFilesCount = 0\n",
    "        restrictedFilesCount = 0\n",
    "        fileTags = []\n",
    "        for file in latestDatasetVersion['files']:            \n",
    "            if 'description' in file:\n",
    "                noFileDescriptionCount = noFileDescriptionCount\n",
    "            else:\n",
    "                noFileDescriptionCount += 1\n",
    "            contentType.append(file['dataFile']['contentType'])\n",
    "            if file['restricted'] == True:\n",
    "                restrictedFilesCount += 1\n",
    "            if file['dataFile']['contentType'] in uningestedFileTypes:\n",
    "                uningestedTabFilesCount += 1\n",
    "            if file['dataFile']['contentType'] == 'text/tab-separated-values':\n",
    "                ingestedTabFilesCount += 1\n",
    "            try:\n",
    "                for tags in file['categories']:\n",
    "                    fileTags.append(tags)\n",
    "            except KeyError:\n",
    "                fileTags = fileTags\n",
    "\n",
    "        tabularDataFileCount = uningestedTabFilesCount + ingestedTabFilesCount\n",
    "\n",
    "        if len(fileTags) == 0:\n",
    "            fileTagsExist = False\n",
    "        else:\n",
    "            fileTagsExist = True\n",
    "\n",
    "        if len(contentType) == 0:\n",
    "            uniqueContentTypes = 'NA'\n",
    "        else:\n",
    "            uniqueContentTypes = list_to_string(list(set(contentType)))\n",
    "\n",
    "        # Create dictionary\n",
    "        newRow = {'datasetPID': datasetPID,\n",
    "                  'datasetPIDUrl' : datasetPID.replace('doi:', 'https://doi.org/'),\n",
    "                  'numberOfVersions': len(datasetVersions['data']),\n",
    "                  'numberOfMajorVersions': latestDatasetVersion['versionNumber'],\n",
    "                  'publicationDate': publicationDate,\n",
    "                  'latestReleaseDate': latestReleaseDate,\n",
    "                  'ageOfDataset(Days)': ageOfDataset,\n",
    "                  'ageOfLastUpdate(Days)': ageOfLastUpdate,\n",
    "                  'descriptionLenth': descriptionLength,\n",
    "                  'termsExist': termsExist,\n",
    "                  'license': license,\n",
    "                  'termsOfUseExists': termsOfUse,\n",
    "                  'termsOfAccessExists': termsOfAccess,\n",
    "                  'relPubCount': relPubCount,\n",
    "                  'relPubPIDCount': relPubPIDCount,\n",
    "                  'usedMetadataBlocks': usedMetadataBlocks,\n",
    "                  'numberOfFiles': numberOfFiles,\n",
    "                  'noFileDescriptionCount': noFileDescriptionCount,\n",
    "                  'fileTagsExist': fileTagsExist,\n",
    "                  'uniqueContentTypes': uniqueContentTypes,\n",
    "                  'tabularDataFileCount': ingestedTabFilesCount + uningestedTabFilesCount,\n",
    "                  'ingestedTabFilesCount': ingestedTabFilesCount,\n",
    "                  'uningestedTabFilesCount': uningestedTabFilesCount,\n",
    "                  'restrictedFilesCount': restrictedFilesCount\n",
    "                 }\n",
    "        rowList.append(dict(newRow))\n",
    "        datasetCount += 1\n",
    "        print('%s of %s (%s)' % (datasetCount, len(get_datasets().index), datasetPID), end='\\r', flush=True)\n",
    "        \n",
    "if len(get_datasets().index) != datasetCount:\n",
    "    print('The metadata of %s dataset(s) could not be retrieved' % (len(datasetPIDs) - datasetCount))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datasetInfoDF = pd.DataFrame(rowList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataframes = [datasetDataverseInfoDF, datasetInfoDF]\n",
    "\n",
    "# For each dataframe, set the indexes (or the common columns across the dataframes to join on)\n",
    "for dataframe in dataframes:\n",
    "    dataframe.set_index(['datasetPID'], inplace=True)\n",
    "\n",
    "# Merge both dataframes and save to report\n",
    "report = reduce(lambda left, right: left.join(right, how='outer'), dataframes)\n",
    "\n",
    "# Reset index\n",
    "report.reset_index(drop=False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datasetPID</th>\n",
       "      <th>dataverseName</th>\n",
       "      <th>dataverseUrl</th>\n",
       "      <th>datasetPIDUrl</th>\n",
       "      <th>numberOfVersions</th>\n",
       "      <th>numberOfMajorVersions</th>\n",
       "      <th>publicationDate</th>\n",
       "      <th>latestReleaseDate</th>\n",
       "      <th>ageOfDataset(Days)</th>\n",
       "      <th>ageOfLastUpdate(Days)</th>\n",
       "      <th>...</th>\n",
       "      <th>relPubPIDCount</th>\n",
       "      <th>usedMetadataBlocks</th>\n",
       "      <th>numberOfFiles</th>\n",
       "      <th>noFileDescriptionCount</th>\n",
       "      <th>fileTagsExist</th>\n",
       "      <th>uniqueContentTypes</th>\n",
       "      <th>tabularDataFileCount</th>\n",
       "      <th>ingestedTabFilesCount</th>\n",
       "      <th>uningestedTabFilesCount</th>\n",
       "      <th>restrictedFilesCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>doi:10.70122/FK2/HZTO03</td>\n",
       "      <td>Julian Gautier (SU) Dataverse</td>\n",
       "      <td>https://demo.dataverse.org/dataverse/sefsef</td>\n",
       "      <td>https://doi.org/10.70122/FK2/HZTO03</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-08-04 19:48:40+00:00</td>\n",
       "      <td>2020-10-26 03:44:39+00:00</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>citation,geospatial</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doi:10.70122/FK2/CMFTOD</td>\n",
       "      <td>Julian Gautier (SU) Dataverse</td>\n",
       "      <td>https://demo.dataverse.org/dataverse/sefsef</td>\n",
       "      <td>https://doi.org/10.70122/FK2/CMFTOD</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-14 20:07:47+00:00</td>\n",
       "      <td>2020-10-14 20:07:47+00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>citation</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>image/jpeg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doi:10.70122/FK2/ZYUGHH</td>\n",
       "      <td>Julian Gautier (SU) Dataverse</td>\n",
       "      <td>https://demo.dataverse.org/dataverse/sefsef</td>\n",
       "      <td>https://doi.org/10.70122/FK2/ZYUGHH</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-09-17 16:08:53+00:00</td>\n",
       "      <td>2020-10-29 03:16:38+00:00</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>astrophysics,biomedical,citation,geospatial,so...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>image/jpeg,image/png,text/tab-separated-values</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                datasetPID                  dataverseName  \\\n",
       "0  doi:10.70122/FK2/HZTO03  Julian Gautier (SU) Dataverse   \n",
       "1  doi:10.70122/FK2/CMFTOD  Julian Gautier (SU) Dataverse   \n",
       "2  doi:10.70122/FK2/ZYUGHH  Julian Gautier (SU) Dataverse   \n",
       "\n",
       "                                  dataverseUrl  \\\n",
       "0  https://demo.dataverse.org/dataverse/sefsef   \n",
       "1  https://demo.dataverse.org/dataverse/sefsef   \n",
       "2  https://demo.dataverse.org/dataverse/sefsef   \n",
       "\n",
       "                         datasetPIDUrl  numberOfVersions  \\\n",
       "0  https://doi.org/10.70122/FK2/HZTO03                 3   \n",
       "1  https://doi.org/10.70122/FK2/CMFTOD                 1   \n",
       "2  https://doi.org/10.70122/FK2/ZYUGHH                16   \n",
       "\n",
       "   numberOfMajorVersions           publicationDate         latestReleaseDate  \\\n",
       "0                      1 2020-08-04 19:48:40+00:00 2020-10-26 03:44:39+00:00   \n",
       "1                      1 2020-10-14 20:07:47+00:00 2020-10-14 20:07:47+00:00   \n",
       "2                      5 2020-09-17 16:08:53+00:00 2020-10-29 03:16:38+00:00   \n",
       "\n",
       "   ageOfDataset(Days)  ageOfLastUpdate(Days)  ...  relPubPIDCount  \\\n",
       "0                  86                      3  ...               0   \n",
       "1                  15                     15  ...               0   \n",
       "2                  42                      0  ...               1   \n",
       "\n",
       "                                  usedMetadataBlocks numberOfFiles  \\\n",
       "0                                citation,geospatial             0   \n",
       "1                                           citation             2   \n",
       "2  astrophysics,biomedical,citation,geospatial,so...             3   \n",
       "\n",
       "   noFileDescriptionCount  fileTagsExist  \\\n",
       "0                       0          False   \n",
       "1                       2          False   \n",
       "2                       2           True   \n",
       "\n",
       "                               uniqueContentTypes  tabularDataFileCount  \\\n",
       "0                                              NA                     0   \n",
       "1                                      image/jpeg                     0   \n",
       "2  image/jpeg,image/png,text/tab-separated-values                     1   \n",
       "\n",
       "  ingestedTabFilesCount  uningestedTabFilesCount  restrictedFilesCount  \n",
       "0                     0                        0                     0  \n",
       "1                     0                        0                     0  \n",
       "2                     1                        0                     0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Export report to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Export report to CSV\n",
    "file = '%s_%s.csv' % (mainDataverseAlias, currentTime)\n",
    "report.to_csv(file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get existing dataverse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.read_csv('mit_datasets.csv', na_filter = False)\n",
    "datasetCount = len(report.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ((len(report[(report['ingestedTabFilesCount']!=0)]))+(len(report[(report['uningestedTabFilesCount']!=0)])))/datasetCount*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of metadatablocks used by all datasets\n",
    "allUsedMetadataBlocks = []\n",
    "for i in report['usedMetadataBlocks']:\n",
    "    allUsedMetadataBlocks.extend(list(i.split(\",\")))\n",
    "\n",
    "# Deduplicate, alphabetize and change list to string\n",
    "allUsedMetadataBlocks = list_to_string(list(set(allUsedMetadataBlocks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of uniqueContentTypes used by all datasets\n",
    "allContentTypes = []\n",
    "for i in report['uniqueContentTypes']:\n",
    "    if i != 'NA':\n",
    "        allContentTypes.extend(list(i.split(\",\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create summary stats of dataverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary\n",
    "summaryDict = {\n",
    "    'Summary': mainDataverseAlias,\n",
    "    'Has description': dataverse_description_exists(),\n",
    "    'Has tagline': dataverse_tagline_exists(),\n",
    "    'Number of search facets': len(dataverse_facets()),\n",
    "    'Metadatablocks enabled': len(dataverse_metadatablocks()) - 1,\n",
    "    'Dataset count': datasetCount,\n",
    "    'Versions (avg # of major and minor versions)': round(report['numberOfVersions'].mean(), 2),\n",
    "    'Major versions (average #)': round(report['numberOfMajorVersions'].mean(), 2),\n",
    "    'Description length (avg # of characters)': round(report['descriptionLenth'].mean(), 2),\n",
    "    'CC0 datasets (% of total datasets)': round((len(report[(report['license'] == 'CC0')]) / datasetCount) * 100, 2),\n",
    "    'Age of datasets (average)': round(report['ageOfDataset(Days)'].mean(), 2),\n",
    "    'No terms (% of datasets with no terms metadata)': round(((~report['termsExist']).values.sum()) / datasetCount * 100, 2),\n",
    "    'Related pub metadata (% of datasets with rel pub metadata)': round(len(report[(report['relPubCount'] != 0)]) / datasetCount * 100, 2),\n",
    "    'Related pub PIDs (% of datasets with rel pub PIDs)': round(len(report[(report['relPubPIDCount'] != 0)]) / datasetCount * 100, 2),\n",
    "    'Metadatablocks used (list)': allUsedMetadataBlocks,\n",
    "    'No files (# of datasets with no files)': len(report[(report['numberOfFiles'] == 0)]),\n",
    "    'File descriptions (% of datasets with 1 or more file descriptions)': round(len(report[(report['noFileDescriptionCount'] != 0)]) / datasetCount * 100, 2),\n",
    "    'File tags (% of datasets with 1 or more file tags)': ((report['fileTagsExist']).values.sum()) / datasetCount * 100,\n",
    "    'Unique file types (count)': len(set(allContentTypes)),\n",
    "    'Tabular data (% of datasets with tabular data) ': round(((len(report[(report['ingestedTabFilesCount'] != 0)])) + (len(report[(report['uningestedTabFilesCount'] != 0)]))) / len(report[(report['numberOfFiles'] != 0)]) * 100, 2),\n",
    "    'Tabular data ingest successes (% of datasets with tabular data that has been ingested)': round(len(report[(report['ingestedTabFilesCount'] != 0)]) / ((len(report[(report['ingestedTabFilesCount'] != 0)])) + (len(report[(report['uningestedTabFilesCount'] != 0)]))) * 100, 2),\n",
    "    'Public files (% of unrestricted files)': round(((report['numberOfFiles'].sum() - report['restrictedFilesCount'].sum()) / report['numberOfFiles'].sum()) * 100, 2)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaryDF = pd.DataFrame.from_records([summaryDict])\n",
    "summaryDF = summaryDF.set_index('Summary').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Summary</th>\n",
       "      <th>mit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Has description</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Has tagline</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number of search facets</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metadatablocks enabled</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset count</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Versions (avg # of major and minor versions)</th>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Major versions (average #)</th>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description length (avg # of characters)</th>\n",
       "      <td>339.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CC0 datasets (% of total datasets)</th>\n",
       "      <td>7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age of datasets (average)</th>\n",
       "      <td>1527.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No terms (% of datasets with no terms metadata)</th>\n",
       "      <td>4.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Related pub metadata (% of datasets with rel pub metadata)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Related pub PIDs (% of datasets with rel pub PIDs)</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metadatablocks used (list)</th>\n",
       "      <td>citation,geospatial,socialscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No files (# of datasets with no files)</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File descriptions (% of datasets with 1 or more file descriptions)</th>\n",
       "      <td>41.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>File tags (% of datasets with 1 or more file tags)</th>\n",
       "      <td>37.6471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unique file types (count)</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular data (% of datasets with tabular data)</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tabular data ingest successes (% of datasets with tabular data that has been ingested)</th>\n",
       "      <td>72.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public files (% of unrestricted files)</th>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Summary                                                                           mit\n",
       "Has description                                                                  True\n",
       "Has tagline                                                                      True\n",
       "Number of search facets                                                             9\n",
       "Metadatablocks enabled                                                              2\n",
       "Dataset count                                                                      85\n",
       "Versions (avg # of major and minor versions)                                     3.55\n",
       "Major versions (average #)                                                       1.71\n",
       "Description length (avg # of characters)                                       339.08\n",
       "CC0 datasets (% of total datasets)                                               7.06\n",
       "Age of datasets (average)                                                     1527.98\n",
       "No terms (% of datasets with no terms metadata)                                  4.71\n",
       "Related pub metadata (% of datasets with rel pu...                                  0\n",
       "Related pub PIDs (% of datasets with rel pub PIDs)                                  0\n",
       "Metadatablocks used (list)                          citation,geospatial,socialscience\n",
       "No files (# of datasets with no files)                                              5\n",
       "File descriptions (% of datasets with 1 or more...                              41.18\n",
       "File tags (% of datasets with 1 or more file tags)                            37.6471\n",
       "Unique file types (count)                                                          26\n",
       "Tabular data (% of datasets with tabular data)                                     55\n",
       "Tabular data ingest successes (% of datasets wi...                              72.73\n",
       "Public files (% of unrestricted files)                                            2.7"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaryDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary to CSV\n",
    "file = '%s_summary_%s.csv' % (mainDataverseAlias, currentTime)\n",
    "summaryDF.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
